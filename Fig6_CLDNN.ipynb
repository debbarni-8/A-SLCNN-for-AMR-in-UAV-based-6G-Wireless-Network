{"cells":[{"cell_type":"code","execution_count":null,"id":"6be5215c","metadata":{"id":"6be5215c"},"outputs":[],"source":["import os\n","import numpy as np\n","from keras.models import Model\n","from keras.layers import Input,Dense,Conv1D,MaxPool1D,ReLU,Dropout,Softmax,concatenate,Conv2D\n","from keras.layers import LSTM,Permute,Reshape,ZeroPadding2D,Activation\n","from keras.utils.vis_utils import plot_model\n","\n","def CLDNNLikeModel(weights=None,\n","             input_shape1=[2,1024],\n","             classes=26,\n","             **kwargs):\n","    if weights is not None and not (os.path.exists(weights)):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization), '\n","                         'or the path to the weights file to be loaded.')\n","\n","\n","    dr = 0.5\n","    input_x = Input(shape=(1, 2, 1024))\n","\n","    input_x_padding = ZeroPadding2D((0, 2), data_format=\"channels_first\")(input_x)\n","\n","    layer11 = Conv2D(50, (1, 8), padding='valid', activation=\"relu\", name=\"conv11\", kernel_initializer=\"glorot_uniform\",\n","                    data_format=\"channels_first\")(input_x_padding)\n","    layer11 = Dropout(dr)(layer11)\n","\n","    layer11_padding = ZeroPadding2D((0, 2), data_format=\"channels_first\")(layer11)\n","    layer12 = Conv2D(50, (1, 8), padding=\"valid\", activation=\"relu\", name=\"conv12\", kernel_initializer=\"glorot_uniform\",\n","                    data_format=\"channels_first\")(layer11_padding)\n","    layer12 = Dropout(dr)(layer12)\n","\n","    layer12 = ZeroPadding2D((0, 2), data_format=\"channels_first\")(layer12)\n","    layer13 = Conv2D(50, (1, 8), padding='valid', activation=\"relu\", name=\"conv13\", kernel_initializer=\"glorot_uniform\",\n","                    data_format=\"channels_first\")(layer12)\n","    layer13 = Dropout(dr)(layer13)\n","\n","    concat = keras.layers.concatenate([layer11, layer13])\n","    concat_size = list(np.shape(concat))\n","    input_dim = int(concat_size[-1] * concat_size[-2])\n","    timesteps = int(concat_size[-3])\n","    concat = Reshape((timesteps, input_dim))(concat)\n","    # （samples，timesteps，input_dim）\n","    lstm_out = LSTM(50, input_dim=input_dim, input_length=timesteps)(concat)\n","    layer_dense1 = Dense(256, activation='relu', kernel_initializer ='he_normal', name=\"dense1\")(lstm_out)\n","    layer_dropout = Dropout(dr)(layer_dense1)\n","    layer_dense2 = Dense(26, kernel_initializer ='he_normal', name=\"dense2\")(layer_dropout)\n","    layer_softmax = Activation('softmax')(layer_dense2)\n","    output = Reshape([26])(layer_softmax)\n","\n","    model = Model(inputs=input_x, outputs=output)\n","\n","    # Load weights.\n","    if weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n","\n","import keras\n","if __name__ == '__main__':\n","    model = CLDNNLikeModel(None,input_shape=(2,1024),classes=24)\n","\n","    adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n","\n","    print('models layers:', model.layers)\n","    print('models config:', model.get_config())\n","    print('models summary:', model.summary())"]},{"cell_type":"code","execution_count":null,"id":"bab042c1","metadata":{"id":"bab042c1"},"outputs":[],"source":["import matplotlib\n","matplotlib.use('TkAgg')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","import csv\n","import itertools\n","from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, mean_absolute_error, r2_score\n","\n","\n","\n","def plot_confusion_matrix(cm, title='', cmap=plt.get_cmap(\"Blues\"), labels=[], save_filename=None):\n","    plt.figure(figsize=(10, 7))\n","    plt.imshow(cm*100, interpolation='nearest', cmap=cmap)\n","    plt.title(title, fontsize=10)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=90, size=12)\n","    plt.yticks(tick_marks, labels, size=12)\n","    for i in range(len(tick_marks)):\n","        for j in range(len(tick_marks)):\n","            if i != j:\n","                text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10)\n","            elif i == j:\n","                color = 'darkorange' if int(np.around(cm[i,j]*100)) == 100 else 'darkorange'\n","                text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10, color=color)\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label', fontdict={'size':16,})\n","    plt.xlabel('Predicted label', fontdict={'size':16,})\n","    if save_filename is not None:\n","        plt.savefig(save_filename, format='pdf', dpi=1200, bbox_inches='tight')\n","    plt.close()\n","\n","def calculate_confusion_matrix(Y, Y_hat, classes):\n","    n_classes = len(classes)\n","    conf = np.zeros([n_classes, n_classes])\n","    confnorm = np.zeros([n_classes, n_classes])\n","\n","    for k in range(0, Y.shape[0]):\n","        i = list(Y[k,:]).index(1)\n","        j = int(np.argmax(Y_hat[k,:]))\n","        conf[i,j] = conf[i,j] + 1\n","\n","    for i in range(0, n_classes):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","\n","    right = np.sum(np.diag(conf))\n","    wrong = np.sum(conf) - right\n","    return confnorm, right, wrong\n","\n","def calculate_acc_at1snr_from_cm(cm):\n","    return np.round(np.diag(cm) / np.sum(cm, axis=1), 3)\n","\n","def calculate_metrics(Y, Y_hat):\n","    Y_true = np.argmax(Y, axis=1)\n","    Y_pred = np.argmax(Y_hat, axis=1)\n","    accuracy = accuracy_score(Y_true, Y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(Y_true, Y_pred, average='weighted')\n","    mse = mean_squared_error(Y_true, Y_pred)\n","    mae = mean_absolute_error(Y_true, Y_pred)\n","    r2 = r2_score(Y_true, Y_pred)\n","\n","    return accuracy, precision, recall, f1\n","\n","def calculate_acc_cm_each_snr(Y, Y_hat, Z, classes=None, save_figure=True, min_snr=0):\n","    Z_array = Z[:, 0]\n","    snrs = sorted(list(set(Z_array)))\n","    acc = np.zeros(len(snrs))\n","    acc_mod_snr = np.zeros((len(classes), len(snrs)))\n","\n","    metrics = {\n","        'accuracy': [],\n","        'precision': [],\n","        'recall': [],\n","        'f1': []\n","    }\n","\n","    i = 0\n","    for snr in snrs:\n","        Y_snr = Y[np.where(Z_array == snr)]\n","        Y_hat_snr = Y_hat[np.where(Z_array == snr)]\n","\n","\n","        accuracy, precision, recall, f1 = calculate_metrics(Y_snr, Y_hat_snr)\n","        metrics['accuracy'].append(accuracy)\n","        metrics['precision'].append(precision)\n","        metrics['recall'].append(recall)\n","        metrics['f1'].append(f1)\n","\n","\n","\n","\n","    # Plot Accuracy, Precision, Recall, F1-Score\n","    for metric, values in metrics.items():\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(snrs, values, label=metric)\n","        for x, y in zip(snrs, values):\n","            plt.text(x, y, round(y, 3), ha='center', va='bottom', fontsize=8)\n","        plt.xlabel(\"Signal to Noise Ratio\")\n","        plt.ylabel(metric.capitalize())\n","        plt.title(f\"{metric.capitalize()} vs SNR\")\n","        plt.legend()\n","        plt.grid()\n","        plt.savefig(f'figure/{metric}_vs_snr.pdf', format='pdf', dpi=1200, bbox_inches='tight')\n","        plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4f124ed2","metadata":{"id":"4f124ed2"},"outputs":[],"source":["import os,random\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","# os.environ[\"THEANO_FLAGS\"]  = \"device=gpu%d\"%(0)\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","#matplotlib.use('Tkagg')\n","import matplotlib.pyplot as plt\n","from matplotlib.collections import LineCollection\n","from matplotlib.colors import ListedColormap, BoundaryNorm\n","import pickle, random, sys,h5py\n","import keras\n","import keras.backend as K\n","from keras.callbacks import LearningRateScheduler,TensorBoard\n","from keras.regularizers import *\n","from keras.optimizers import Adam\n","from keras.models import model_from_json\n","from keras.utils.np_utils import to_categorical\n","\n","classes = ['BPSK',\n","               'QPSK',\n","               '8PSK',\n","               '16PSK',\n","               '32PSK',\n","               '64PSK',\n","               '4QAM',\n","               '8QAM',\n","               '16QAM',\n","               '32QAM',\n","               '64QAM',\n","               '128QAM',\n","               '256QAM',\n","               '2FSK',\n","               '4FSK',\n","               '8FSK',\n","               '16FSK',\n","               '4PAM',\n","               '8PAM',\n","               '16PAM',\n","               'AM-DSB',\n","               'AM-DSB-SC',\n","               'AM-USB',\n","               'AM-LSB',\n","                'FM',\n","                'PM']"]},{"cell_type":"code","execution_count":null,"id":"5158e821","metadata":{"id":"5158e821"},"outputs":[],"source":["##traindata\n","data1 = h5py.File('Dataset/HisarMod2019.1/Train/train.mat','r')\n","train=data1['data_save'][:]\n","train=train.swapaxes(0,2)\n","\n","data2 = h5py.File('Dataset/HisarMod2019.1/Test/test.mat','r')\n","test=data2['data_save'][:]\n","test=test.swapaxes(0,2)\n","\n","train=np.expand_dims(train,axis=1)\n","test=np.expand_dims(test,axis=1)"]},{"cell_type":"code","execution_count":null,"id":"2a4bc948","metadata":{"id":"2a4bc948"},"outputs":[],"source":["##label\n","train_labels = pd.read_csv('Dataset/HisarMod2019.1/Train/train_labels1.csv',header=None)\n","train_labels=np.array(train_labels)\n","train_labels = to_categorical(train_labels, num_classes=None)\n","\n","test_labels = pd.read_csv('Dataset/HisarMod2019.1/Test/test_labels1.csv',header=None)\n","test_labels =np.array(test_labels)\n","test_labels = to_categorical(test_labels, num_classes=None)\n","\n","##snr\n","train_snr=pd.read_csv('Dataset/HisarMod2019.1/Train/train_snr.csv',header=None)\n","train_snr=np.array(train_snr)\n","\n","test_snr=pd.read_csv('Dataset/HisarMod2019.1/Test/test_snr.csv' ,header=None)\n","test_snr=np.array(test_snr)"]},{"cell_type":"code","execution_count":null,"id":"1b900716","metadata":{"id":"1b900716"},"outputs":[],"source":["# [N,1024,2]\n","n_examples = train.shape[0]\n","n_train = int(n_examples * 0.8)\n","n_val = int(n_examples * 0.2)\n","train_idx = list(np.random.choice(range(0, n_examples), size=n_train, replace=False))\n","val_idx = list(set(range(0, n_examples)) - set(train_idx))\n","np.random.shuffle(train_idx)\n","np.random.shuffle(val_idx)\n","X_train = train[train_idx]\n","Y_train = train_labels[train_idx]\n","X_val = train[val_idx]\n","Y_val = train_labels[val_idx]\n","X_test = test\n","Y_test = test_labels\n","Z_test = test_snr"]},{"cell_type":"code","execution_count":null,"id":"3f7e2179","metadata":{"id":"3f7e2179"},"outputs":[],"source":["# Set up some params\n","nb_epoch = 200     # number of epochs to train on\n","batch_size = 300  # training batch size"]},{"cell_type":"code","execution_count":null,"id":"f28ed861","metadata":{"id":"f28ed861"},"outputs":[],"source":["model = CLDNNLikeModel(None,input_shape=[2,1024])\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n","plot_model(model, to_file='model_CLDNN.png',show_shapes=True) # print model"]},{"cell_type":"code","execution_count":null,"id":"104d7307","metadata":{"id":"104d7307"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"id":"f129012d","metadata":{"id":"f129012d"},"outputs":[],"source":["filepath = 'weights/CLDNN.h5'\n","import time\n","TRS_CLDNN=time.time()\n","history = model.fit(X_train,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=nb_epoch,\n","    verbose=2,\n","    validation_data=(X_val,Y_val),\n","    callbacks = [#reduce_lr,\n","                keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n","                keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,verbose=1,patince=5,min_lr=0.0000001),\n","                keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='auto'),\n","                #keras.callbacks.TensorBoard(log_dir='./logs/',histogram_freq=1,write_graph=False,write_grads=1,write_images=False,update_freq='epoch')\n","                ]\n","                    )"]},{"cell_type":"code","execution_count":null,"id":"dac8986f","metadata":{"id":"dac8986f"},"outputs":[],"source":["TRE_CLDNN=time.time()\n","T_CLDNN=TRE_CLDNN-TRS_CLDNN"]},{"cell_type":"code","execution_count":null,"id":"22e43739","metadata":{"id":"22e43739"},"outputs":[],"source":["#Show simple version of performances\n","TES_CLDNN=time.time()\n","score = model.evaluate(X_test, Y_test, verbose=1, batch_size=batch_size)\n","print(score)"]},{"cell_type":"code","source":["calculate_acc_cm_each_snr(Y_test, test_Y_hat, Z_test, classes, min_snr=-18)"],"metadata":{"id":"QPqAbyD47JjH"},"id":"QPqAbyD47JjH","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"200d0dde","metadata":{"id":"200d0dde"},"outputs":[],"source":["TEE_CLDNN=time.time()\n","T_CLDNN=TEE_CLDNN-TES_CLDNN"]},{"cell_type":"code","execution_count":null,"id":"2698f656","metadata":{"id":"2698f656"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}