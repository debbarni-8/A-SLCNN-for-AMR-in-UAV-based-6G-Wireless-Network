{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1CKxjoUDDWbzovwBOKWn1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5EHqn6wQRg2o"},"outputs":[],"source":["import os\n","from keras.models import Model\n","from keras.layers import Input,Dense,ReLU,Dropout,Softmax,Conv2D,MaxPool2D,Lambda,GaussianNoise\n","from keras.layers import Bidirectional,Flatten,CuDNNGRU\n","from keras.utils.vis_utils import plot_model\n","\n","def ICAMC(weights=None,\n","             input_shape=[2,1024],\n","             classes=26,\n","             **kwargs):\n","    if weights is not None and not (os.path.exists(weights)):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization), '\n","                         'or the path to the weights file to be loaded.')\n","    dr = 0.45\n","    input = Input(input_shape+[1],name='input')\n","    x=Conv2D(32,(1,8), activation=\"relu\", name=\"conv1\", padding='same', kernel_initializer='glorot_uniform')(input)\n","    x= MaxPool2D(pool_size=(2, 2))(x)\n","    x=Conv2D(32,(1,4), activation=\"relu\", name=\"conv2\", padding='same', kernel_initializer='glorot_uniform')(x)\n","    x=Conv2D(64,(1,8),activation=\"relu\", name=\"conv3\", padding='same', kernel_initializer='glorot_uniform')(x)\n","    x = Dropout(dr)(x)\n","    x=Conv2D(64,(1,8), activation=\"relu\", name=\"conv4\", padding='same', kernel_initializer='glorot_uniform')(x)\n","    x = Dropout(dr)(x)\n","    x=Flatten()(x)\n","    x = Dense(64,activation='relu',name='dense1')(x)\n","    x=Dropout(dr)(x)\n","    x = GaussianNoise(1)(x)\n","    x = Dense(26,activation='softmax',name='dense2')(x)\n","\n","    model = Model(inputs = input,outputs = x)\n","\n","    # Load weights.\n","    if weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n","\n","import keras\n","if __name__ == '__main__':\n","    model =  ICAMC(None,input_shape=[2,1024],classes=26)\n","\n","    adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n","\n","    print('models layers:', model.layers)\n","    print('models config:', model.get_config())\n","    print('models summary:', model.summary())"]},{"cell_type":"code","source":["import matplotlib\n","matplotlib.use('TkAgg')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","import csv\n","import itertools\n","from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, mean_absolute_error, r2_score\n","\n","# Show loss curves\n","def show_history(history):\n","    plt.figure()\n","    plt.title('Training loss performance')\n","    plt.xlabel('Epoch', fontdict={'size':16,})\n","    plt.ylabel('Loss', fontdict={'size':16,})\n","    plt.plot(history.epoch, history.history['loss'], label='train loss', marker='>', linewidth=2)\n","    plt.plot(history.epoch, history.history['val_loss'], label='validation loss', marker='*', linewidth=2)\n","    plt.legend()\n","    plt.savefig('figure/total_loss.pdf', format='pdf', dpi=1200, bbox_inches = 'tight')\n","    plt.close()\n","\n","def plot_confusion_matrix(cm, title='', cmap=plt.get_cmap(\"Blues\"), labels=[], save_filename=None):\n","    plt.figure(figsize=(10, 7))\n","    plt.imshow(cm*100, interpolation='nearest', cmap=cmap)\n","    plt.title(title, fontsize=10)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=90, size=12)\n","    plt.yticks(tick_marks, labels, size=12)\n","    for i in range(len(tick_marks)):\n","        for j in range(len(tick_marks)):\n","            if i != j:\n","                text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10)\n","            elif i == j:\n","                color = 'darkorange' if int(np.around(cm[i,j]*100)) == 100 else 'darkorange'\n","                text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10, color=color)\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label', fontdict={'size':16,})\n","    plt.xlabel('Predicted label', fontdict={'size':16,})\n","    if save_filename is not None:\n","        plt.savefig(save_filename, format='pdf', dpi=1200, bbox_inches='tight')\n","    plt.close()\n","\n","def calculate_confusion_matrix(Y, Y_hat, classes):\n","    n_classes = len(classes)\n","    conf = np.zeros([n_classes, n_classes])\n","    confnorm = np.zeros([n_classes, n_classes])\n","\n","    for k in range(0, Y.shape[0]):\n","        i = list(Y[k,:]).index(1)\n","        j = int(np.argmax(Y_hat[k,:]))\n","        conf[i,j] = conf[i,j] + 1\n","\n","    for i in range(0, n_classes):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","\n","    right = np.sum(np.diag(conf))\n","    wrong = np.sum(conf) - right\n","    return confnorm, right, wrong\n","\n","def calculate_acc_at1snr_from_cm(cm):\n","    return np.round(np.diag(cm) / np.sum(cm, axis=1), 3)\n","\n","def calculate_metrics(Y, Y_hat):\n","    Y_true = np.argmax(Y, axis=1)\n","    Y_pred = np.argmax(Y_hat, axis=1)\n","    accuracy = accuracy_score(Y_true, Y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(Y_true, Y_pred, average='weighted')\n","    mse = mean_squared_error(Y_true, Y_pred)\n","    mae = mean_absolute_error(Y_true, Y_pred)\n","    r2 = r2_score(Y_true, Y_pred)\n","\n","    return accuracy, precision, recall, f1\n","\n","def calculate_acc_cm_each_snr(Y, Y_hat, Z, classes=None, save_figure=True, min_snr=0):\n","    Z_array = Z[:, 0]\n","    snrs = sorted(list(set(Z_array)))\n","    acc = np.zeros(len(snrs))\n","    acc_mod_snr = np.zeros((len(classes), len(snrs)))\n","\n","    metrics = {\n","        'accuracy': [],\n","        'precision': [],\n","        'recall': [],\n","        'f1': []\n","    }\n","\n","    i = 0\n","    for snr in snrs:\n","        Y_snr = Y[np.where(Z_array == snr)]\n","        Y_hat_snr = Y_hat[np.where(Z_array == snr)]\n","\n","        cm, right, wrong = calculate_confusion_matrix(Y_snr, Y_hat_snr, classes)\n","        accuracy, precision, recall, f1 = calculate_metrics(Y_snr, Y_hat_snr)\n","\n","        metrics['accuracy'].append(accuracy)\n","        metrics['precision'].append(precision)\n","        metrics['recall'].append(recall)\n","        metrics['f1'].append(f1)\n","\n","        if snr >= min_snr:\n","            plot_confusion_matrix(cm, cmap=plt.cm.Blues, labels=classes, save_filename='figure/cm_snr{}.pdf'.format(snr))\n","\n","        acc[i] = round(1.0 * right / (right + wrong), 3)\n","        print('Accuracy at %ddb: %.2f%s / (%d + %d)' % (snr, 100*acc[i], '%', right, wrong))\n","        acc_mod_snr[:, i] = calculate_acc_at1snr_from_cm(cm)\n","        i += 1\n","\n","    fd = open('acc_overall_128k_on_512k_wts.dat', 'wb')\n","    pickle.dump(('128k', '512k', acc), fd)\n","    fd.close()\n","\n","    # Plot Accuracy, Precision, Recall, F1-Score\n","    for metric, values in metrics.items():\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(snrs, values, label=metric)\n","        for x, y in zip(snrs, values):\n","            plt.text(x, y, round(y, 3), ha='center', va='bottom', fontsize=8)\n","        plt.xlabel(\"Signal to Noise Ratio\")\n","        plt.ylabel(metric.capitalize())\n","        plt.title(f\"{metric.capitalize()} vs SNR\")\n","        plt.legend()\n","        plt.grid()\n","        plt.savefig(f'figure/{metric}_vs_snr.pdf', format='pdf', dpi=1200, bbox_inches='tight')\n","        plt.show()\n","\n","    # Plot recognition accuracy for each modulation at different SNRs\n","    dis_num = 7\n","    marker = itertools.cycle(('D', '*', 'o' , '>', '<', 'P', 'H'))\n","    for g in range(int(np.ceil(acc_mod_snr.shape[0] / dis_num))):\n","        beg_index = g * dis_num\n","        end_index = np.min([(g + 1) * dis_num, acc_mod_snr.shape[0]])\n","        plt.figure(figsize=(12, 10))\n","        plt.xlabel(\"Signal to Noise Ratio (dB)\", fontdict={'size': 20,})\n","        plt.ylabel(\"Recognition Accuracy (%)\", fontdict={'size': 20,})\n","        for i in range(beg_index, end_index):\n","            plt.plot(snrs, acc_mod_snr[i], label=classes[i], marker=next(marker), linewidth=3, markersize=12)\n","        plt.legend(fontsize=24)\n","        plt.grid()\n","        if save_figure:\n","            plt.savefig('figure/acc_with_mod_{}.pdf'.format(g + 1), format='pdf', dpi=1200, bbox_inches='tight')\n","        plt.show()"],"metadata":{"id":"Q6PH4BGjR7MI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","from matplotlib.collections import LineCollection\n","from matplotlib.colors import ListedColormap, BoundaryNorm\n","import sys,h5py\n","import tensorflow as tf\n","\n","import pandas as pd\n","from keras.utils.np_utils import to_categorical\n","classes = ['BPSK',\n","               'QPSK',\n","               '8PSK',\n","               '16PSK',\n","               '32PSK',\n","               '64PSK',\n","               '4QAM',\n","               '8QAM',\n","               '16QAM',\n","               '32QAM',\n","               '64QAM',\n","               '128QAM',\n","               '256QAM',\n","               '2FSK',\n","               '4FSK',\n","               '8FSK',\n","               '16FSK',\n","               '4PAM',\n","               '8PAM',\n","               '16PAM',\n","               'AM-DSB',\n","               'AM-DSB-SC',\n","               'AM-USB',\n","               'AM-LSB',\n","                'FM',\n","                'PM']"],"metadata":{"id":"BBFoDfqDSeRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##traindata\n","data1 = h5py.File('Dataset/HisarMod2019.1/Train/train.mat','r')\n","train=data1['data_save'][:]\n","train=train.swapaxes(0,2)\n","\n","data2 = h5py.File('Dataset/HisarMod2019.1/Test/test.mat','r')\n","test=data2['data_save'][:]\n","test=test.swapaxes(0,2)\n","train=np.expand_dims(train,axis=3)\n","test=np.expand_dims(test,axis=3)"],"metadata":{"id":"ybOeAdmhSkcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##label\n","train_labels = pd.read_csv('Dataset/HisarMod2019.1/Train/train_labels1.csv',header=None)\n","train_labels=np.array(train_labels)\n","train_labels = to_categorical(train_labels, num_classes=None)\n","\n","test_labels = pd.read_csv('Dataset/HisarMod2019.1/Test/test_labels1.csv',header=None)\n","test_labels =np.array(test_labels)\n","test_labels = to_categorical(test_labels, num_classes=None)"],"metadata":{"id":"qW3nMIR3SwYs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##snr\n","train_snr=pd.read_csv('Dataset/HisarMod2019.1/Train/train_snr.csv',header=None)\n","train_snr=np.array(train_snr)\n","\n","test_snr=pd.read_csv('Dataset/HisarMod2019.1/Test/test_snr.csv',header=None)\n","test_snr=np.array(test_snr)"],"metadata":{"id":"0AwPhnZMTJgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_examples = train.shape[0]\n","n_train = int(n_examples * 0.6)\n","n_val = int(n_examples * 0.15)\n","train_idx = list(np.random.choice(range(0, n_examples), size=n_train, replace=False))\n","val_idx = list(set(range(0, n_examples)) - set(train_idx))\n","np.random.shuffle(train_idx)\n","np.random.shuffle(val_idx)\n","X_train = train[train_idx]\n","Y_train = train_labels[train_idx]\n","X_val = train[val_idx]\n","Y_val = train_labels[val_idx]\n","X_test = test\n","Y_test = test_labels\n","Z_test = test_snr"],"metadata":{"id":"smgOu26mTNkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up some params\n","nb_epoch = 200     # number of epochs to train on\n","batch_size = 300  # training batch size"],"metadata":{"id":"9yLT3r4DTW6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model=ICAMC()\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","plot_model(model, to_file='model.png',show_shapes=True) # print model\n","model.summary()"],"metadata":{"id":"H5pAnhAqTa1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filepath = 'weights/weights.h5'\n","import time\n","TRS_PROPOSED=time.time()"],"metadata":{"id":"RPbpPiBdTedO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(X_train,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=nb_epoch,\n","    verbose=2,\n","    validation_data=(X_val,Y_val),\n","    callbacks = [\n","                keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n","                keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,verbose=1,patince=5,min_lr=0.0000001),\n","                keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n","\n","                ]\n","                    )"],"metadata":{"id":"_83BlNanTihN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRE_PROPOSED=time.time()\n","T_PROPOSED=TRE_PROPOSED-TRS_PROPOSED\n","T_PROPOSED"],"metadata":{"id":"ms1S55M0TtUj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Show simple version of performance\n","TES_PROPOSED=time.time()\n","score = model.evaluate(X_test, Y_test, verbose=1, batch_size=batch_size)\n","print(score)"],"metadata":{"id":"gLx2F55gUSFY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_history(history)"],"metadata":{"id":"YRiuseqsIPCO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(model):\n","    model.load_weights(filepath)\n","    # Plot confusion matrix\n","    test_Y_hat = model.predict(X_test, batch_size=batch_size)\n","    cm, right, wrong = calculate_confusion_matrix(Y_test, test_Y_hat, classes)\n","    acc = round(1.0 * right / (right + wrong), 4)\n","    print('Overall Accuracy:%.2f%s / (%d + %d)' % (100 * acc, '%', right, wrong))\n","    plot_confusion_matrix(cm, labels=['BPSK',\n","                                      'QPSK',\n","                                      '8PSK',\n","                                      '16PSK',\n","                                      '32PSK',\n","                                      '64PSK',\n","                                      '4QAM',\n","                                      '8QAM',\n","                                      '16QAM',\n","                                      '32QAM',\n","                                      '64QAM',\n","                                      '128QAM',\n","                                      '256QAM',\n","                                      '2FSK',\n","                                      '4FSK',\n","                                      '8FSK',\n","                                      '16FSK',\n","                                      '4PAM',\n","                                      '8PAM',\n","                                      '16PAM',\n","                                      'AM-DSB',\n","                                      'AM-DSB-SC',\n","                                      'AM-USB',\n","                                      'AM-LSB',\n","                                      'FM',\n","                                      'PM'], save_filename='figure/total_confusion.png')\n","    calculate_acc_cm_each_snr(Y_test, test_Y_hat, Z_test, classes, min_snr=-18)"],"metadata":{"id":"X9BJfQoiq6_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict(model)"],"metadata":{"id":"laOlXt4Mrpuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TEE_PROPOSED=time.time()\n","TE_PROPOSED=TEE_PROPOSED-TES_PROPOSED"],"metadata":{"id":"1BBUAMOOxV7Q"},"execution_count":null,"outputs":[]}]}