{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1cfc85e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "1cfc85e5",
        "outputId": "cb14ed4f-d6f9-4d83-a3d2-f668cabb2689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models layers: [<InputLayer name=input, built=True>, <Conv2D name=conv1, built=True>, <MaxPooling2D name=max_pooling2d_2, built=True>, <Conv2D name=conv2, built=True>, <Conv2D name=conv3, built=True>, <MaxPooling2D name=max_pooling2d_3, built=True>, <Dropout name=dropout_3, built=True>, <Conv2D name=conv4, built=True>, <Dropout name=dropout_4, built=True>, <Flatten name=flatten_1, built=True>, <Dense name=dense1, built=True>, <Dropout name=dropout_5, built=True>, <GaussianNoise name=gaussian_noise_1, built=True>, <Dense name=dense2, built=True>]\n",
            "models config: {'name': 'functional_1', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 2, 1024, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input'}, 'registered_name': None, 'name': 'input', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 32, 'kernel_size': (1, 8), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 2, 1024, 1)}, 'name': 'conv1', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 2, 1024, 1), 'dtype': 'float32', 'keras_history': ['input', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}, 'registered_name': None, 'name': 'max_pooling2d_2', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 2, 1024, 32), 'dtype': 'float32', 'keras_history': ['conv1', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 32, 'kernel_size': (1, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 1, 512, 32)}, 'name': 'conv2', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 1, 512, 32), 'dtype': 'float32', 'keras_history': ['max_pooling2d_2', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 64, 'kernel_size': (1, 8), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 1, 512, 32)}, 'name': 'conv3', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 1, 512, 32), 'dtype': 'float32', 'keras_history': ['conv2', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'pool_size': (1, 1), 'padding': 'valid', 'strides': (1, 1), 'data_format': 'channels_last'}, 'registered_name': None, 'name': 'max_pooling2d_3', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 1, 512, 64), 'dtype': 'float32', 'keras_history': ['conv3', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'rate': 0.45, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'name': 'dropout_3', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 1, 512, 64), 'dtype': 'float32', 'keras_history': ['max_pooling2d_3', 0, 0]}},), 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv4', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 64, 'kernel_size': (1, 8), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 1, 512, 64)}, 'name': 'conv4', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 1, 512, 64), 'dtype': 'float32', 'keras_history': ['dropout_3', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'rate': 0.45, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'name': 'dropout_4', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 1, 512, 64), 'dtype': 'float32', 'keras_history': ['conv4', 0, 0]}},), 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': (None, 1, 512, 64)}, 'name': 'flatten_1', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 1, 512, 64), 'dtype': 'float32', 'keras_history': ['dropout_4', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 64, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 32768)}, 'name': 'dense1', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 32768), 'dtype': 'float32', 'keras_history': ['flatten_1', 0, 0]}},), 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'rate': 0.45, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'name': 'dropout_5', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 64), 'dtype': 'float32', 'keras_history': ['dense1', 0, 0]}},), 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'GaussianNoise', 'config': {'name': 'gaussian_noise_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'stddev': 1, 'seed': None}, 'registered_name': None, 'name': 'gaussian_noise_1', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 64), 'dtype': 'float32', 'keras_history': ['dropout_5', 0, 0]}},), 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 26, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 64)}, 'name': 'dense2', 'inbound_nodes': [{'args': ({'class_name': '__keras_tensor__', 'config': {'shape': (None, 64), 'dtype': 'float32', 'keras_history': ['gaussian_noise_1', 0, 0]}},), 'kwargs': {}}]}], 'input_layers': [['input', 0, 0]], 'output_layers': [['dense2', 0, 0]]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m288\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m16,448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv4 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m32,832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m2,097,216\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m1,690\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,216</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,152,602\u001b[0m (8.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,152,602</span> (8.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,152,602\u001b[0m (8.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,152,602</span> (8.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models summary: None\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,Dense,ReLU,Dropout,Softmax,Conv2D,MaxPool2D,Lambda,GaussianNoise\n",
        "from keras.layers import Bidirectional,Flatten,CuDNNGRU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "def ICAMC(weights=None,\n",
        "             input_shape=[2,1024],\n",
        "             classes=26,\n",
        "             **kwargs):\n",
        "    if weights is not None and not (os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "    dr = 0.45\n",
        "    input = Input(input_shape+[1],name='input')\n",
        "    x=Conv2D(32,(1,8), activation=\"relu\", name=\"conv1\", padding='same', kernel_initializer='glorot_uniform')(input)\n",
        "    x= MaxPool2D(pool_size=(2, 2))(x)\n",
        "    x=Conv2D(32,(1,4), activation=\"relu\", name=\"conv2\", padding='same', kernel_initializer='glorot_uniform')(x)\n",
        "    x=Conv2D(64,(1,8),activation=\"relu\", name=\"conv3\", padding='same', kernel_initializer='glorot_uniform')(x)\n",
        "    x = MaxPool2D(pool_size=(1, 1))(x)\n",
        "    x = Dropout(dr)(x)\n",
        "    x=Conv2D(64,(1,8), activation=\"relu\", name=\"conv4\", padding='same', kernel_initializer='glorot_uniform')(x)\n",
        "    x = Dropout(dr)(x)\n",
        "    x=Flatten()(x)\n",
        "    x = Dense(64,activation='relu',name='dense1')(x)\n",
        "    x=Dropout(dr)(x)\n",
        "    x = GaussianNoise(1)(x)\n",
        "    x = Dense(26,activation='softmax',name='dense2')(x)\n",
        "\n",
        "    model = Model(inputs = input,outputs = x)\n",
        "\n",
        "    # Load weights.\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "import keras\n",
        "if __name__ == '__main__':\n",
        "    model =  ICAMC(None,input_shape=[2,1024],classes=26)\n",
        "\n",
        "    adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "\n",
        "    print('models layers:', model.layers)\n",
        "    print('models config:', model.get_config())\n",
        "    print('models summary:', model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71191ca",
      "metadata": {
        "id": "d71191ca"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.use('TkAgg')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import csv\n",
        "import itertools\n",
        "from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Show loss curves\n",
        "def show_history(history):\n",
        "    plt.figure()\n",
        "    plt.title('Training loss performance')\n",
        "    plt.xlabel('Epoch', fontdict={'size':16,})\n",
        "    plt.ylabel('Loss', fontdict={'size':16,})\n",
        "    plt.plot(history.epoch, history.history['loss'], label='train loss', marker='>', linewidth=2)\n",
        "    plt.plot(history.epoch, history.history['val_loss'], label='validation loss', marker='*', linewidth=2)\n",
        "    plt.legend()\n",
        "    plt.savefig('figure/total_loss.pdf', format='pdf', dpi=1200, bbox_inches = 'tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(cm, title='', cmap=plt.get_cmap(\"Blues\"), labels=[], save_filename=None):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(cm*100, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=10)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=90, size=12)\n",
        "    plt.yticks(tick_marks, labels, size=12)\n",
        "    for i in range(len(tick_marks)):\n",
        "        for j in range(len(tick_marks)):\n",
        "            if i != j:\n",
        "                text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10)\n",
        "            elif i == j:\n",
        "                color = 'darkorange' if int(np.around(cm[i,j]*100)) == 100 else 'darkorange'\n",
        "                text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10, color=color)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label', fontdict={'size':16,})\n",
        "    plt.xlabel('Predicted label', fontdict={'size':16,})\n",
        "    if save_filename is not None:\n",
        "        plt.savefig(save_filename, format='pdf', dpi=1200, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def calculate_confusion_matrix(Y, Y_hat, classes):\n",
        "    n_classes = len(classes)\n",
        "    conf = np.zeros([n_classes, n_classes])\n",
        "    confnorm = np.zeros([n_classes, n_classes])\n",
        "\n",
        "    for k in range(0, Y.shape[0]):\n",
        "        i = list(Y[k,:]).index(1)\n",
        "        j = int(np.argmax(Y_hat[k,:]))\n",
        "        conf[i,j] = conf[i,j] + 1\n",
        "\n",
        "    for i in range(0, n_classes):\n",
        "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        "\n",
        "    right = np.sum(np.diag(conf))\n",
        "    wrong = np.sum(conf) - right\n",
        "    return confnorm, right, wrong\n",
        "\n",
        "def calculate_acc_at1snr_from_cm(cm):\n",
        "    return np.round(np.diag(cm) / np.sum(cm, axis=1), 3)\n",
        "\n",
        "def calculate_metrics(Y, Y_hat):\n",
        "    Y_true = np.argmax(Y, axis=1)\n",
        "    Y_pred = np.argmax(Y_hat, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(Y_true, Y_pred, average='weighted')\n",
        "    mse = mean_squared_error(Y_true, Y_pred)\n",
        "    mae = mean_absolute_error(Y_true, Y_pred)\n",
        "    r2 = r2_score(Y_true, Y_pred)\n",
        "\n",
        "    return precision, recall, f1, mse, mae, r2\n",
        "\n",
        "def calculate_acc_cm_each_snr(Y, Y_hat, Z, classes=None, save_figure=True, min_snr=0):\n",
        "    Z_array = Z[:, 0]\n",
        "    snrs = sorted(list(set(Z_array)))\n",
        "    acc = np.zeros(len(snrs))\n",
        "    acc_mod_snr = np.zeros((len(classes), len(snrs)))\n",
        "\n",
        "    metrics = {\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': [],\n",
        "        'mse': [],\n",
        "        'mae': [],\n",
        "        'r2': []\n",
        "    }\n",
        "\n",
        "    i = 0\n",
        "    for snr in snrs:\n",
        "        Y_snr = Y[np.where(Z_array == snr)]\n",
        "        Y_hat_snr = Y_hat[np.where(Z_array == snr)]\n",
        "\n",
        "        cm, right, wrong = calculate_confusion_matrix(Y_snr, Y_hat_snr, classes)\n",
        "        precision, recall, f1, mse, mae, r2 = calculate_metrics(Y_snr, Y_hat_snr)\n",
        "\n",
        "        metrics['precision'].append(precision)\n",
        "        metrics['recall'].append(recall)\n",
        "        metrics['f1'].append(f1)\n",
        "        metrics['mse'].append(mse)\n",
        "        metrics['mae'].append(mae)\n",
        "        metrics['r2'].append(r2)\n",
        "\n",
        "        if snr >= min_snr:\n",
        "            plot_confusion_matrix(cm, cmap=plt.cm.Blues, labels=classes, save_filename='figure/cm_snr{}.pdf'.format(snr))\n",
        "\n",
        "        acc[i] = round(1.0 * right / (right + wrong), 3)\n",
        "        print('Accuracy at %ddb: %.2f%s / (%d + %d)' % (snr, 100*acc[i], '%', right, wrong))\n",
        "        acc_mod_snr[:, i] = calculate_acc_at1snr_from_cm(cm)\n",
        "        i += 1\n",
        "\n",
        "    fd = open('acc_overall_128k_on_512k_wts.dat', 'wb')\n",
        "    pickle.dump(('128k', '512k', acc), fd)\n",
        "    fd.close()\n",
        "\n",
        "    # Plot Accuracy, Precision, Recall, F1-Score, MSE, MAE, and R2\n",
        "    for metric, values in metrics.items():\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(snrs, values, label=metric)\n",
        "        for x, y in zip(snrs, values):\n",
        "            plt.text(x, y, round(y, 3), ha='center', va='bottom', fontsize=8)\n",
        "        plt.xlabel(\"Signal to Noise Ratio\")\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.title(f\"{metric.capitalize()} vs SNR\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.savefig(f'figure/{metric}_vs_snr.pdf', format='pdf', dpi=1200, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    # Plot recognition accuracy for each modulation at different SNRs\n",
        "    dis_num = 7\n",
        "    marker = itertools.cycle(('D', '*', 'o' , '>', '<', 'P', 'H'))\n",
        "    for g in range(int(np.ceil(acc_mod_snr.shape[0] / dis_num))):\n",
        "        beg_index = g * dis_num\n",
        "        end_index = np.min([(g + 1) * dis_num, acc_mod_snr.shape[0]])\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        plt.xlabel(\"Signal to Noise Ratio (dB)\", fontdict={'size': 20,})\n",
        "        plt.ylabel(\"Recognition Accuracy (%)\", fontdict={'size': 20,})\n",
        "        for i in range(beg_index, end_index):\n",
        "            plt.plot(snrs, acc_mod_snr[i], label=classes[i], marker=next(marker), linewidth=3, markersize=12)\n",
        "        plt.legend(fontsize=24)\n",
        "        plt.grid()\n",
        "        if save_figure:\n",
        "            plt.savefig('figure/acc_with_mod_{}.pdf'.format(g + 1), format='pdf', dpi=1200, bbox_inches='tight')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab93c632",
      "metadata": {
        "id": "ab93c632"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "from matplotlib.collections import LineCollection\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "import sys,h5py\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "classes = ['BPSK',\n",
        "               'QPSK',\n",
        "               '8PSK',\n",
        "               '16PSK',\n",
        "               '32PSK',\n",
        "               '64PSK',\n",
        "               '4QAM',\n",
        "               '8QAM',\n",
        "               '16QAM',\n",
        "               '32QAM',\n",
        "               '64QAM',\n",
        "               '128QAM',\n",
        "               '256QAM',\n",
        "               '2FSK',\n",
        "               '4FSK',\n",
        "               '8FSK',\n",
        "               '16FSK',\n",
        "               '4PAM',\n",
        "               '8PAM',\n",
        "               '16PAM',\n",
        "               'AM-DSB',\n",
        "               'AM-DSB-SC',\n",
        "               'AM-USB',\n",
        "               'AM-LSB',\n",
        "                'FM',\n",
        "                'PM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc26fc93",
      "metadata": {
        "id": "bc26fc93"
      },
      "outputs": [],
      "source": [
        "##traindata\n",
        "data1 = h5py.File('Dataset/HisarMod2019.1/Train/train.mat','r')\n",
        "train=data1['data_save'][:]\n",
        "train=train.swapaxes(0,2)\n",
        "\n",
        "data2 = h5py.File('Dataset/HisarMod2019.1/Test/test.mat','r')\n",
        "test=data2['data_save'][:]\n",
        "test=test.swapaxes(0,2)\n",
        "train=np.expand_dims(train,axis=3)\n",
        "test=np.expand_dims(test,axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2839c91",
      "metadata": {
        "id": "c2839c91"
      },
      "outputs": [],
      "source": [
        "##label\n",
        "train_labels = pd.read_csv('Dataset/HisarMod2019.1/Train/train_labels1.csv',header=None)\n",
        "train_labels=np.array(train_labels)\n",
        "train_labels = to_categorical(train_labels, num_classes=None)\n",
        "\n",
        "test_labels = pd.read_csv('Dataset/HisarMod2019.1/Test/test_labels1.csv',header=None)\n",
        "test_labels =np.array(test_labels)\n",
        "test_labels = to_categorical(test_labels, num_classes=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5231007a",
      "metadata": {
        "id": "5231007a"
      },
      "outputs": [],
      "source": [
        "##snr\n",
        "train_snr=pd.read_csv('Dataset/HisarMod2019.1/Train/train_snr.csv',header=None)\n",
        "train_snr=np.array(train_snr)\n",
        "\n",
        "test_snr=pd.read_csv('Dataset/HisarMod2019.1/Test/test_snr.csv',header=None)\n",
        "test_snr=np.array(test_snr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412923d0",
      "metadata": {
        "id": "412923d0"
      },
      "outputs": [],
      "source": [
        "n_examples = train.shape[0]\n",
        "n_train = int(n_examples * 0.6)\n",
        "n_val = int(n_examples * 0.15)\n",
        "train_idx = list(np.random.choice(range(0, n_examples), size=n_train, replace=False))\n",
        "val_idx = list(set(range(0, n_examples)) - set(train_idx))\n",
        "np.random.shuffle(train_idx)\n",
        "np.random.shuffle(val_idx)\n",
        "X_train = train[train_idx]\n",
        "Y_train = train_labels[train_idx]\n",
        "X_val = train[val_idx]\n",
        "Y_val = train_labels[val_idx]\n",
        "X_test = test\n",
        "Y_test = test_labels\n",
        "Z_test = test_snr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1070fc",
      "metadata": {
        "id": "eb1070fc"
      },
      "outputs": [],
      "source": [
        "# Set up some params\n",
        "nb_epoch = 200     # number of epochs to train on\n",
        "batch_size = 300  # training batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f85a7cdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "f85a7cdc",
        "outputId": "77f2e6e7-ba0c-475f-9897-8678d9b68998"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m288\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m16,448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv4 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m32,832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m2,097,216\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m1,690\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,216</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,152,602\u001b[0m (8.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,152,602</span> (8.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,152,602\u001b[0m (8.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,152,602</span> (8.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model=ICAMC()\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "plot_model(model, to_file='model.png',show_shapes=True) # print model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6e7084",
      "metadata": {
        "id": "bd6e7084"
      },
      "outputs": [],
      "source": [
        "filepath = 'weights/weights.h5'\n",
        "import time\n",
        "TRS_PROPOSED=time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671d509d",
      "metadata": {
        "id": "671d509d",
        "outputId": "c388e4b8-f9dd-42f8-8b97-13e211a4df50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.70053, saving model to weights\\weights.h5\n",
            "1040/1040 - 114s - loss: 2.2761 - accuracy: 0.2723 - val_loss: 1.7005 - val_accuracy: 0.3702 - lr: 0.0010 - 114s/epoch - 109ms/step\n",
            "Epoch 2/200\n",
            "\n",
            "Epoch 2: val_loss improved from 1.70053 to 1.55928, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.7105 - accuracy: 0.3712 - val_loss: 1.5593 - val_accuracy: 0.4068 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 3/200\n",
            "\n",
            "Epoch 3: val_loss improved from 1.55928 to 1.44801, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.5971 - accuracy: 0.4041 - val_loss: 1.4480 - val_accuracy: 0.4463 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 4/200\n",
            "\n",
            "Epoch 4: val_loss improved from 1.44801 to 1.38589, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 1.5252 - accuracy: 0.4250 - val_loss: 1.3859 - val_accuracy: 0.4632 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 5/200\n",
            "\n",
            "Epoch 5: val_loss improved from 1.38589 to 1.35080, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.4735 - accuracy: 0.4417 - val_loss: 1.3508 - val_accuracy: 0.4915 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 6: val_loss improved from 1.35080 to 1.31181, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.4204 - accuracy: 0.4631 - val_loss: 1.3118 - val_accuracy: 0.5165 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 7: val_loss improved from 1.31181 to 1.28284, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.3774 - accuracy: 0.4813 - val_loss: 1.2828 - val_accuracy: 0.5398 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 8: val_loss improved from 1.28284 to 1.26273, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 1.3376 - accuracy: 0.4988 - val_loss: 1.2627 - val_accuracy: 0.5449 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 9: val_loss improved from 1.26273 to 1.18868, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.1887 - val_accuracy: 0.5784 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 10: val_loss improved from 1.18868 to 1.10887, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.2603 - accuracy: 0.5336 - val_loss: 1.1089 - val_accuracy: 0.6102 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 11: val_loss improved from 1.10887 to 1.09749, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.2290 - accuracy: 0.5469 - val_loss: 1.0975 - val_accuracy: 0.6223 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 12: val_loss improved from 1.09749 to 1.06192, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 1.1947 - accuracy: 0.5628 - val_loss: 1.0619 - val_accuracy: 0.6406 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 13: val_loss improved from 1.06192 to 1.03832, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.1618 - accuracy: 0.5765 - val_loss: 1.0383 - val_accuracy: 0.6528 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 14: val_loss improved from 1.03832 to 1.00076, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.1326 - accuracy: 0.5886 - val_loss: 1.0008 - val_accuracy: 0.6690 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 15: val_loss improved from 1.00076 to 0.96829, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.1040 - accuracy: 0.5995 - val_loss: 0.9683 - val_accuracy: 0.6799 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 16: val_loss improved from 0.96829 to 0.95506, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.0855 - accuracy: 0.6083 - val_loss: 0.9551 - val_accuracy: 0.6911 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 17: val_loss improved from 0.95506 to 0.94903, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.0566 - accuracy: 0.6202 - val_loss: 0.9490 - val_accuracy: 0.6873 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 18/200\n",
            "\n",
            "Epoch 18: val_loss improved from 0.94903 to 0.90454, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.0349 - accuracy: 0.6288 - val_loss: 0.9045 - val_accuracy: 0.7052 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 19: val_loss improved from 0.90454 to 0.90304, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 1.0161 - accuracy: 0.6353 - val_loss: 0.9030 - val_accuracy: 0.7037 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 20/200\n",
            "\n",
            "Epoch 20: val_loss improved from 0.90304 to 0.87603, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.9977 - accuracy: 0.6439 - val_loss: 0.8760 - val_accuracy: 0.7144 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 21/200\n",
            "\n",
            "Epoch 21: val_loss improved from 0.87603 to 0.85868, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.9769 - accuracy: 0.6501 - val_loss: 0.8587 - val_accuracy: 0.7187 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 22/200\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.85868\n",
            "1040/1040 - 71s - loss: 0.9646 - accuracy: 0.6555 - val_loss: 0.8677 - val_accuracy: 0.7180 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 23/200\n",
            "\n",
            "Epoch 23: val_loss improved from 0.85868 to 0.84934, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.9478 - accuracy: 0.6621 - val_loss: 0.8493 - val_accuracy: 0.7206 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 24: val_loss improved from 0.84934 to 0.81078, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.9328 - accuracy: 0.6687 - val_loss: 0.8108 - val_accuracy: 0.7316 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 25/200\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.81078\n",
            "1040/1040 - 71s - loss: 0.9170 - accuracy: 0.6739 - val_loss: 0.8183 - val_accuracy: 0.7304 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 26/200\n",
            "\n",
            "Epoch 26: val_loss improved from 0.81078 to 0.80149, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.9104 - accuracy: 0.6773 - val_loss: 0.8015 - val_accuracy: 0.7349 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 27/200\n",
            "\n",
            "Epoch 27: val_loss improved from 0.80149 to 0.78915, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.8925 - accuracy: 0.6845 - val_loss: 0.7892 - val_accuracy: 0.7387 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 28/200\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.78915\n",
            "1040/1040 - 71s - loss: 0.8802 - accuracy: 0.6882 - val_loss: 0.8204 - val_accuracy: 0.7353 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 29/200\n",
            "\n",
            "Epoch 29: val_loss improved from 0.78915 to 0.77120, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.8713 - accuracy: 0.6911 - val_loss: 0.7712 - val_accuracy: 0.7418 - lr: 0.0010 - 72s/epoch - 70ms/step\n",
            "Epoch 30/200\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.77120\n",
            "1040/1040 - 71s - loss: 0.8598 - accuracy: 0.6956 - val_loss: 0.7737 - val_accuracy: 0.7426 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 31/200\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.77120\n",
            "1040/1040 - 71s - loss: 0.8535 - accuracy: 0.6986 - val_loss: 0.7863 - val_accuracy: 0.7426 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 32/200\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.77120\n",
            "1040/1040 - 71s - loss: 0.8379 - accuracy: 0.7036 - val_loss: 0.7725 - val_accuracy: 0.7430 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 33/200\n",
            "\n",
            "Epoch 33: val_loss improved from 0.77120 to 0.74913, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.8318 - accuracy: 0.7056 - val_loss: 0.7491 - val_accuracy: 0.7508 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 34/200\n",
            "\n",
            "Epoch 34: val_loss improved from 0.74913 to 0.74886, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.8211 - accuracy: 0.7099 - val_loss: 0.7489 - val_accuracy: 0.7529 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 35/200\n",
            "\n",
            "Epoch 35: val_loss improved from 0.74886 to 0.74569, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.8119 - accuracy: 0.7141 - val_loss: 0.7457 - val_accuracy: 0.7515 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 36/200\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.74569\n",
            "1040/1040 - 71s - loss: 0.8074 - accuracy: 0.7138 - val_loss: 0.7635 - val_accuracy: 0.7487 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 37/200\n",
            "\n",
            "Epoch 37: val_loss improved from 0.74569 to 0.73989, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.8016 - accuracy: 0.7181 - val_loss: 0.7399 - val_accuracy: 0.7560 - lr: 0.0010 - 71s/epoch - 69ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/200\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.73989\n",
            "1040/1040 - 71s - loss: 0.7863 - accuracy: 0.7223 - val_loss: 0.7411 - val_accuracy: 0.7547 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 39/200\n",
            "\n",
            "Epoch 39: val_loss improved from 0.73989 to 0.72690, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.7856 - accuracy: 0.7242 - val_loss: 0.7269 - val_accuracy: 0.7583 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 40/200\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.72690\n",
            "1040/1040 - 71s - loss: 0.7801 - accuracy: 0.7255 - val_loss: 0.7307 - val_accuracy: 0.7552 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 41/200\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.72690\n",
            "1040/1040 - 71s - loss: 0.7685 - accuracy: 0.7292 - val_loss: 0.7286 - val_accuracy: 0.7574 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 42/200\n",
            "\n",
            "Epoch 42: val_loss improved from 0.72690 to 0.70952, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.7639 - accuracy: 0.7320 - val_loss: 0.7095 - val_accuracy: 0.7623 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 43/200\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.70952\n",
            "1040/1040 - 71s - loss: 0.7608 - accuracy: 0.7330 - val_loss: 0.7260 - val_accuracy: 0.7599 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 44/200\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.70952\n",
            "1040/1040 - 71s - loss: 0.7553 - accuracy: 0.7350 - val_loss: 0.7304 - val_accuracy: 0.7581 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 45/200\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.70952\n",
            "1040/1040 - 71s - loss: 0.7471 - accuracy: 0.7387 - val_loss: 0.7257 - val_accuracy: 0.7610 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 46/200\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.70952\n",
            "1040/1040 - 71s - loss: 0.7413 - accuracy: 0.7396 - val_loss: 0.7286 - val_accuracy: 0.7607 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 47/200\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.70952\n",
            "1040/1040 - 71s - loss: 0.7364 - accuracy: 0.7413 - val_loss: 0.7201 - val_accuracy: 0.7611 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 48/200\n",
            "\n",
            "Epoch 48: val_loss improved from 0.70952 to 0.70144, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.7306 - accuracy: 0.7443 - val_loss: 0.7014 - val_accuracy: 0.7666 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 49/200\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.70144\n",
            "1040/1040 - 71s - loss: 0.7258 - accuracy: 0.7460 - val_loss: 0.7134 - val_accuracy: 0.7627 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 50/200\n",
            "\n",
            "Epoch 50: val_loss improved from 0.70144 to 0.69158, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.7239 - accuracy: 0.7474 - val_loss: 0.6916 - val_accuracy: 0.7683 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 51/200\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.69158\n",
            "1040/1040 - 71s - loss: 0.7151 - accuracy: 0.7500 - val_loss: 0.6974 - val_accuracy: 0.7688 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 52/200\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.69158\n",
            "1040/1040 - 71s - loss: 0.7101 - accuracy: 0.7518 - val_loss: 0.7126 - val_accuracy: 0.7643 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 53/200\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.69158\n",
            "1040/1040 - 71s - loss: 0.7089 - accuracy: 0.7525 - val_loss: 0.6999 - val_accuracy: 0.7649 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 54/200\n",
            "\n",
            "Epoch 54: val_loss improved from 0.69158 to 0.68724, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.6984 - accuracy: 0.7563 - val_loss: 0.6872 - val_accuracy: 0.7704 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 55/200\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.68724\n",
            "1040/1040 - 71s - loss: 0.6950 - accuracy: 0.7574 - val_loss: 0.7125 - val_accuracy: 0.7655 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 56/200\n",
            "\n",
            "Epoch 56: val_loss improved from 0.68724 to 0.68501, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.6958 - accuracy: 0.7574 - val_loss: 0.6850 - val_accuracy: 0.7699 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 57/200\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.68501\n",
            "1040/1040 - 71s - loss: 0.6852 - accuracy: 0.7619 - val_loss: 0.6965 - val_accuracy: 0.7657 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 58/200\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.68501\n",
            "1040/1040 - 70s - loss: 0.6846 - accuracy: 0.7615 - val_loss: 0.6949 - val_accuracy: 0.7675 - lr: 0.0010 - 70s/epoch - 68ms/step\n",
            "Epoch 59/200\n",
            "\n",
            "Epoch 59: val_loss improved from 0.68501 to 0.68292, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.6802 - accuracy: 0.7640 - val_loss: 0.6829 - val_accuracy: 0.7709 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 60/200\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.68292\n",
            "1040/1040 - 70s - loss: 0.6761 - accuracy: 0.7642 - val_loss: 0.6860 - val_accuracy: 0.7710 - lr: 0.0010 - 70s/epoch - 67ms/step\n",
            "Epoch 61/200\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.68292\n",
            "1040/1040 - 71s - loss: 0.6731 - accuracy: 0.7658 - val_loss: 0.6879 - val_accuracy: 0.7716 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 62/200\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.68292\n",
            "1040/1040 - 71s - loss: 0.6672 - accuracy: 0.7674 - val_loss: 0.7591 - val_accuracy: 0.7548 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 63/200\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.68292\n",
            "1040/1040 - 71s - loss: 0.6664 - accuracy: 0.7682 - val_loss: 0.6908 - val_accuracy: 0.7702 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 64/200\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.68292\n",
            "1040/1040 - 71s - loss: 0.6580 - accuracy: 0.7702 - val_loss: 0.6898 - val_accuracy: 0.7716 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 65/200\n",
            "\n",
            "Epoch 65: val_loss improved from 0.68292 to 0.66479, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.6582 - accuracy: 0.7714 - val_loss: 0.6648 - val_accuracy: 0.7770 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 66/200\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.66479\n",
            "1040/1040 - 71s - loss: 0.6508 - accuracy: 0.7732 - val_loss: 0.6737 - val_accuracy: 0.7753 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 67/200\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.66479\n",
            "1040/1040 - 71s - loss: 0.6501 - accuracy: 0.7738 - val_loss: 0.6670 - val_accuracy: 0.7762 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 68/200\n",
            "\n",
            "Epoch 68: val_loss improved from 0.66479 to 0.66156, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.6476 - accuracy: 0.7753 - val_loss: 0.6616 - val_accuracy: 0.7775 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 69/200\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.66156\n",
            "1040/1040 - 71s - loss: 0.6436 - accuracy: 0.7766 - val_loss: 0.6760 - val_accuracy: 0.7759 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 70/200\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.66156\n",
            "1040/1040 - 71s - loss: 0.6374 - accuracy: 0.7785 - val_loss: 0.6946 - val_accuracy: 0.7721 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 71/200\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.66156\n",
            "1040/1040 - 71s - loss: 0.6363 - accuracy: 0.7800 - val_loss: 0.6951 - val_accuracy: 0.7698 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 72/200\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.66156\n",
            "1040/1040 - 71s - loss: 0.6354 - accuracy: 0.7798 - val_loss: 0.6923 - val_accuracy: 0.7736 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 73/200\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.66156\n",
            "1040/1040 - 71s - loss: 0.6319 - accuracy: 0.7805 - val_loss: 0.6872 - val_accuracy: 0.7735 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 74/200\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.66156\n",
            "1040/1040 - 71s - loss: 0.6281 - accuracy: 0.7819 - val_loss: 0.6619 - val_accuracy: 0.7799 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 75/200\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.66156\n",
            "1040/1040 - 71s - loss: 0.6266 - accuracy: 0.7839 - val_loss: 0.6699 - val_accuracy: 0.7757 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 76/200\n",
            "\n",
            "Epoch 76: val_loss improved from 0.66156 to 0.65929, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.6212 - accuracy: 0.7843 - val_loss: 0.6593 - val_accuracy: 0.7805 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 77/200\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.65929\n",
            "1040/1040 - 71s - loss: 0.6189 - accuracy: 0.7849 - val_loss: 0.6640 - val_accuracy: 0.7789 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 78/200\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.65929\n",
            "1040/1040 - 71s - loss: 0.6135 - accuracy: 0.7875 - val_loss: 0.6612 - val_accuracy: 0.7781 - lr: 0.0010 - 71s/epoch - 68ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79/200\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.65929\n",
            "1040/1040 - 71s - loss: 0.6091 - accuracy: 0.7889 - val_loss: 0.6790 - val_accuracy: 0.7764 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 80/200\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.65929\n",
            "1040/1040 - 71s - loss: 0.6114 - accuracy: 0.7880 - val_loss: 0.6617 - val_accuracy: 0.7815 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 81/200\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.65929\n",
            "1040/1040 - 71s - loss: 0.6068 - accuracy: 0.7899 - val_loss: 0.6698 - val_accuracy: 0.7763 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 82/200\n",
            "\n",
            "Epoch 82: val_loss improved from 0.65929 to 0.65643, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.6059 - accuracy: 0.7905 - val_loss: 0.6564 - val_accuracy: 0.7830 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 83/200\n",
            "\n",
            "Epoch 83: val_loss improved from 0.65643 to 0.65162, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.5995 - accuracy: 0.7914 - val_loss: 0.6516 - val_accuracy: 0.7820 - lr: 0.0010 - 71s/epoch - 69ms/step\n",
            "Epoch 84/200\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.65162\n",
            "1040/1040 - 71s - loss: 0.6011 - accuracy: 0.7924 - val_loss: 0.6610 - val_accuracy: 0.7794 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 85/200\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.65162\n",
            "1040/1040 - 71s - loss: 0.5983 - accuracy: 0.7935 - val_loss: 0.6517 - val_accuracy: 0.7801 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 86/200\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.65162\n",
            "1040/1040 - 71s - loss: 0.5937 - accuracy: 0.7944 - val_loss: 0.6555 - val_accuracy: 0.7805 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 87/200\n",
            "\n",
            "Epoch 87: val_loss improved from 0.65162 to 0.64623, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.5932 - accuracy: 0.7941 - val_loss: 0.6462 - val_accuracy: 0.7833 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 88/200\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5925 - accuracy: 0.7953 - val_loss: 0.6637 - val_accuracy: 0.7777 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 89/200\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5890 - accuracy: 0.7955 - val_loss: 0.6617 - val_accuracy: 0.7790 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 90/200\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5882 - accuracy: 0.7955 - val_loss: 0.6544 - val_accuracy: 0.7812 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 91/200\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5840 - accuracy: 0.7978 - val_loss: 0.6507 - val_accuracy: 0.7817 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 92/200\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5866 - accuracy: 0.7983 - val_loss: 0.6614 - val_accuracy: 0.7785 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 93/200\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5836 - accuracy: 0.7984 - val_loss: 0.6603 - val_accuracy: 0.7800 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 94/200\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5826 - accuracy: 0.7979 - val_loss: 0.6528 - val_accuracy: 0.7825 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 95/200\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.64623\n",
            "1040/1040 - 71s - loss: 0.5773 - accuracy: 0.8007 - val_loss: 0.6661 - val_accuracy: 0.7780 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 96/200\n",
            "\n",
            "Epoch 96: val_loss improved from 0.64623 to 0.64244, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.5725 - accuracy: 0.8019 - val_loss: 0.6424 - val_accuracy: 0.7848 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 97/200\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.64244\n",
            "1040/1040 - 71s - loss: 0.5705 - accuracy: 0.8025 - val_loss: 0.6686 - val_accuracy: 0.7782 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 98/200\n",
            "\n",
            "Epoch 98: val_loss improved from 0.64244 to 0.64233, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.5720 - accuracy: 0.8023 - val_loss: 0.6423 - val_accuracy: 0.7857 - lr: 0.0010 - 72s/epoch - 69ms/step\n",
            "Epoch 99/200\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5710 - accuracy: 0.8023 - val_loss: 0.6610 - val_accuracy: 0.7813 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 100/200\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5684 - accuracy: 0.8036 - val_loss: 0.6572 - val_accuracy: 0.7811 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 101/200\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5658 - accuracy: 0.8051 - val_loss: 0.6467 - val_accuracy: 0.7848 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 102/200\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5624 - accuracy: 0.8062 - val_loss: 0.6554 - val_accuracy: 0.7846 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 103/200\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5657 - accuracy: 0.8052 - val_loss: 0.6474 - val_accuracy: 0.7837 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 104/200\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5605 - accuracy: 0.8066 - val_loss: 0.6436 - val_accuracy: 0.7853 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 105/200\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5544 - accuracy: 0.8089 - val_loss: 0.6541 - val_accuracy: 0.7842 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 106/200\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5580 - accuracy: 0.8084 - val_loss: 0.6539 - val_accuracy: 0.7834 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 107/200\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.64233\n",
            "1040/1040 - 71s - loss: 0.5533 - accuracy: 0.8092 - val_loss: 0.6523 - val_accuracy: 0.7856 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 108/200\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.64233\n",
            "\n",
            "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1040/1040 - 71s - loss: 0.5520 - accuracy: 0.8097 - val_loss: 0.6439 - val_accuracy: 0.7861 - lr: 0.0010 - 71s/epoch - 68ms/step\n",
            "Epoch 109/200\n",
            "\n",
            "Epoch 109: val_loss improved from 0.64233 to 0.62592, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.5097 - accuracy: 0.8220 - val_loss: 0.6259 - val_accuracy: 0.7911 - lr: 5.0000e-04 - 72s/epoch - 69ms/step\n",
            "Epoch 110/200\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.62592\n",
            "1040/1040 - 71s - loss: 0.4983 - accuracy: 0.8261 - val_loss: 0.6295 - val_accuracy: 0.7898 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 111/200\n",
            "\n",
            "Epoch 111: val_loss improved from 0.62592 to 0.61597, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.4933 - accuracy: 0.8268 - val_loss: 0.6160 - val_accuracy: 0.7937 - lr: 5.0000e-04 - 72s/epoch - 69ms/step\n",
            "Epoch 112/200\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4890 - accuracy: 0.8291 - val_loss: 0.6222 - val_accuracy: 0.7939 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 113/200\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4857 - accuracy: 0.8295 - val_loss: 0.6357 - val_accuracy: 0.7892 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 114/200\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4830 - accuracy: 0.8305 - val_loss: 0.6405 - val_accuracy: 0.7864 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 115/200\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4793 - accuracy: 0.8318 - val_loss: 0.6178 - val_accuracy: 0.7933 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 116/200\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4780 - accuracy: 0.8324 - val_loss: 0.6207 - val_accuracy: 0.7927 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 117/200\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4750 - accuracy: 0.8336 - val_loss: 0.6321 - val_accuracy: 0.7897 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 118/200\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4741 - accuracy: 0.8342 - val_loss: 0.6176 - val_accuracy: 0.7933 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 119/200\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4717 - accuracy: 0.8341 - val_loss: 0.6184 - val_accuracy: 0.7940 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 120/200\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.61597\n",
            "1040/1040 - 71s - loss: 0.4709 - accuracy: 0.8349 - val_loss: 0.6311 - val_accuracy: 0.7896 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 121/200\n",
            "\n",
            "Epoch 121: val_loss improved from 0.61597 to 0.61238, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.4668 - accuracy: 0.8360 - val_loss: 0.6124 - val_accuracy: 0.7945 - lr: 5.0000e-04 - 72s/epoch - 69ms/step\n",
            "Epoch 122/200\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4678 - accuracy: 0.8354 - val_loss: 0.6309 - val_accuracy: 0.7900 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 123/200\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4651 - accuracy: 0.8367 - val_loss: 0.6277 - val_accuracy: 0.7913 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 124/200\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4634 - accuracy: 0.8380 - val_loss: 0.6172 - val_accuracy: 0.7946 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 125/200\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4627 - accuracy: 0.8375 - val_loss: 0.6527 - val_accuracy: 0.7881 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 126/200\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4572 - accuracy: 0.8389 - val_loss: 0.6166 - val_accuracy: 0.7940 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 127/200\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4563 - accuracy: 0.8384 - val_loss: 0.6184 - val_accuracy: 0.7942 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 128/200\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4590 - accuracy: 0.8387 - val_loss: 0.6144 - val_accuracy: 0.7950 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 129/200\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4550 - accuracy: 0.8396 - val_loss: 0.6222 - val_accuracy: 0.7936 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 130/200\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4532 - accuracy: 0.8407 - val_loss: 0.6306 - val_accuracy: 0.7922 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 131/200\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.61238\n",
            "\n",
            "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "1040/1040 - 71s - loss: 0.4547 - accuracy: 0.8400 - val_loss: 0.6370 - val_accuracy: 0.7912 - lr: 5.0000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 132/200\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.61238\n",
            "1040/1040 - 71s - loss: 0.4277 - accuracy: 0.8482 - val_loss: 0.6221 - val_accuracy: 0.7941 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 133/200\n",
            "\n",
            "Epoch 133: val_loss improved from 0.61238 to 0.60908, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.4249 - accuracy: 0.8497 - val_loss: 0.6091 - val_accuracy: 0.7978 - lr: 2.5000e-04 - 72s/epoch - 69ms/step\n",
            "Epoch 134/200\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.60908\n",
            "1040/1040 - 71s - loss: 0.4242 - accuracy: 0.8504 - val_loss: 0.6250 - val_accuracy: 0.7950 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 135/200\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.60908\n",
            "1040/1040 - 71s - loss: 0.4238 - accuracy: 0.8503 - val_loss: 0.6128 - val_accuracy: 0.7973 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 136/200\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.60908\n",
            "1040/1040 - 71s - loss: 0.4215 - accuracy: 0.8502 - val_loss: 0.6162 - val_accuracy: 0.7961 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 137/200\n",
            "\n",
            "Epoch 137: val_loss improved from 0.60908 to 0.60614, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.4186 - accuracy: 0.8516 - val_loss: 0.6061 - val_accuracy: 0.7981 - lr: 2.5000e-04 - 72s/epoch - 69ms/step\n",
            "Epoch 138/200\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.60614\n",
            "1040/1040 - 71s - loss: 0.4169 - accuracy: 0.8521 - val_loss: 0.6117 - val_accuracy: 0.7969 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 139/200\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.60614\n",
            "1040/1040 - 71s - loss: 0.4168 - accuracy: 0.8523 - val_loss: 0.6062 - val_accuracy: 0.7987 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 140/200\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.60614\n",
            "1040/1040 - 71s - loss: 0.4151 - accuracy: 0.8529 - val_loss: 0.6130 - val_accuracy: 0.7983 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 141/200\n",
            "\n",
            "Epoch 141: val_loss improved from 0.60614 to 0.60334, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.4147 - accuracy: 0.8526 - val_loss: 0.6033 - val_accuracy: 0.7983 - lr: 2.5000e-04 - 71s/epoch - 69ms/step\n",
            "Epoch 142/200\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.60334\n",
            "1040/1040 - 71s - loss: 0.4118 - accuracy: 0.8539 - val_loss: 0.6096 - val_accuracy: 0.7982 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 143/200\n",
            "\n",
            "Epoch 143: val_loss did not improve from 0.60334\n",
            "1040/1040 - 71s - loss: 0.4146 - accuracy: 0.8537 - val_loss: 0.6052 - val_accuracy: 0.7978 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 144/200\n",
            "\n",
            "Epoch 144: val_loss improved from 0.60334 to 0.60333, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.4136 - accuracy: 0.8530 - val_loss: 0.6033 - val_accuracy: 0.7985 - lr: 2.5000e-04 - 71s/epoch - 69ms/step\n",
            "Epoch 145/200\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.60333\n",
            "1040/1040 - 71s - loss: 0.4122 - accuracy: 0.8534 - val_loss: 0.6056 - val_accuracy: 0.7982 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 146/200\n",
            "\n",
            "Epoch 146: val_loss did not improve from 0.60333\n",
            "1040/1040 - 71s - loss: 0.4074 - accuracy: 0.8557 - val_loss: 0.6089 - val_accuracy: 0.7975 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 147/200\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.60333\n",
            "1040/1040 - 71s - loss: 0.4069 - accuracy: 0.8566 - val_loss: 0.6068 - val_accuracy: 0.7983 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 148/200\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.60333\n",
            "1040/1040 - 71s - loss: 0.4081 - accuracy: 0.8560 - val_loss: 0.6036 - val_accuracy: 0.7992 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 149/200\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.60333\n",
            "1040/1040 - 71s - loss: 0.4075 - accuracy: 0.8562 - val_loss: 0.6035 - val_accuracy: 0.7981 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 150/200\n",
            "\n",
            "Epoch 150: val_loss improved from 0.60333 to 0.60103, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.4047 - accuracy: 0.8565 - val_loss: 0.6010 - val_accuracy: 0.8000 - lr: 2.5000e-04 - 72s/epoch - 69ms/step\n",
            "Epoch 151/200\n",
            "\n",
            "Epoch 151: val_loss did not improve from 0.60103\n",
            "1040/1040 - 71s - loss: 0.4059 - accuracy: 0.8560 - val_loss: 0.6023 - val_accuracy: 0.7988 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 152/200\n",
            "\n",
            "Epoch 152: val_loss did not improve from 0.60103\n",
            "1040/1040 - 71s - loss: 0.4037 - accuracy: 0.8565 - val_loss: 0.6096 - val_accuracy: 0.7994 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 153/200\n",
            "\n",
            "Epoch 153: val_loss did not improve from 0.60103\n",
            "1040/1040 - 71s - loss: 0.4001 - accuracy: 0.8572 - val_loss: 0.6080 - val_accuracy: 0.7989 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 154/200\n",
            "\n",
            "Epoch 154: val_loss did not improve from 0.60103\n",
            "1040/1040 - 71s - loss: 0.4019 - accuracy: 0.8572 - val_loss: 0.6034 - val_accuracy: 0.7991 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 155/200\n",
            "\n",
            "Epoch 155: val_loss did not improve from 0.60103\n",
            "1040/1040 - 71s - loss: 0.4031 - accuracy: 0.8569 - val_loss: 0.6014 - val_accuracy: 0.8013 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 156/200\n",
            "\n",
            "Epoch 156: val_loss did not improve from 0.60103\n",
            "1040/1040 - 71s - loss: 0.3985 - accuracy: 0.8579 - val_loss: 0.6039 - val_accuracy: 0.7999 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 157/200\n",
            "\n",
            "Epoch 157: val_loss improved from 0.60103 to 0.60041, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.4003 - accuracy: 0.8575 - val_loss: 0.6004 - val_accuracy: 0.7998 - lr: 2.5000e-04 - 72s/epoch - 69ms/step\n",
            "Epoch 158/200\n",
            "\n",
            "Epoch 158: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3978 - accuracy: 0.8587 - val_loss: 0.6051 - val_accuracy: 0.7988 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 159/200\n",
            "\n",
            "Epoch 159: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3972 - accuracy: 0.8586 - val_loss: 0.6041 - val_accuracy: 0.7993 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 160/200\n",
            "\n",
            "Epoch 160: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3962 - accuracy: 0.8589 - val_loss: 0.6083 - val_accuracy: 0.8005 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 161/200\n",
            "\n",
            "Epoch 161: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3974 - accuracy: 0.8580 - val_loss: 0.6050 - val_accuracy: 0.8006 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 162/200\n",
            "\n",
            "Epoch 162: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3951 - accuracy: 0.8598 - val_loss: 0.6052 - val_accuracy: 0.7988 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 163/200\n",
            "\n",
            "Epoch 163: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3952 - accuracy: 0.8602 - val_loss: 0.6029 - val_accuracy: 0.8014 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 164/200\n",
            "\n",
            "Epoch 164: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3942 - accuracy: 0.8599 - val_loss: 0.6020 - val_accuracy: 0.8003 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 165/200\n",
            "\n",
            "Epoch 165: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3960 - accuracy: 0.8601 - val_loss: 0.6010 - val_accuracy: 0.8009 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 166/200\n",
            "\n",
            "Epoch 166: val_loss did not improve from 0.60041\n",
            "1040/1040 - 71s - loss: 0.3929 - accuracy: 0.8607 - val_loss: 0.6088 - val_accuracy: 0.8004 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 167/200\n",
            "\n",
            "Epoch 167: val_loss did not improve from 0.60041\n",
            "\n",
            "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "1040/1040 - 71s - loss: 0.3939 - accuracy: 0.8598 - val_loss: 0.6062 - val_accuracy: 0.8001 - lr: 2.5000e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 168/200\n",
            "\n",
            "Epoch 168: val_loss improved from 0.60041 to 0.59664, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.3831 - accuracy: 0.8634 - val_loss: 0.5966 - val_accuracy: 0.8017 - lr: 1.2500e-04 - 71s/epoch - 69ms/step\n",
            "Epoch 169/200\n",
            "\n",
            "Epoch 169: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3815 - accuracy: 0.8646 - val_loss: 0.6071 - val_accuracy: 0.8006 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 170/200\n",
            "\n",
            "Epoch 170: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3786 - accuracy: 0.8651 - val_loss: 0.6026 - val_accuracy: 0.8019 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 171/200\n",
            "\n",
            "Epoch 171: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3789 - accuracy: 0.8642 - val_loss: 0.6009 - val_accuracy: 0.8022 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 172/200\n",
            "\n",
            "Epoch 172: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3785 - accuracy: 0.8647 - val_loss: 0.5989 - val_accuracy: 0.8019 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 173/200\n",
            "\n",
            "Epoch 173: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3788 - accuracy: 0.8654 - val_loss: 0.6064 - val_accuracy: 0.8014 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 174/200\n",
            "\n",
            "Epoch 174: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3789 - accuracy: 0.8648 - val_loss: 0.6019 - val_accuracy: 0.8019 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 175/200\n",
            "\n",
            "Epoch 175: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3745 - accuracy: 0.8664 - val_loss: 0.5977 - val_accuracy: 0.8029 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 176/200\n",
            "\n",
            "Epoch 176: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3756 - accuracy: 0.8657 - val_loss: 0.5981 - val_accuracy: 0.8021 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 177/200\n",
            "\n",
            "Epoch 177: val_loss did not improve from 0.59664\n",
            "1040/1040 - 71s - loss: 0.3768 - accuracy: 0.8655 - val_loss: 0.6010 - val_accuracy: 0.8011 - lr: 1.2500e-04 - 71s/epoch - 68ms/step\n",
            "Epoch 178/200\n",
            "\n",
            "Epoch 178: val_loss improved from 0.59664 to 0.59662, saving model to weights\\weights.h5\n",
            "\n",
            "Epoch 178: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "1040/1040 - 71s - loss: 0.3770 - accuracy: 0.8654 - val_loss: 0.5966 - val_accuracy: 0.8027 - lr: 1.2500e-04 - 71s/epoch - 69ms/step\n",
            "Epoch 179/200\n",
            "\n",
            "Epoch 179: val_loss did not improve from 0.59662\n",
            "1040/1040 - 71s - loss: 0.3710 - accuracy: 0.8673 - val_loss: 0.5983 - val_accuracy: 0.8020 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 180/200\n",
            "\n",
            "Epoch 180: val_loss did not improve from 0.59662\n",
            "1040/1040 - 71s - loss: 0.3674 - accuracy: 0.8679 - val_loss: 0.5999 - val_accuracy: 0.8032 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 181/200\n",
            "\n",
            "Epoch 181: val_loss improved from 0.59662 to 0.59656, saving model to weights\\weights.h5\n",
            "1040/1040 - 72s - loss: 0.3663 - accuracy: 0.8688 - val_loss: 0.5966 - val_accuracy: 0.8032 - lr: 6.2500e-05 - 72s/epoch - 69ms/step\n",
            "Epoch 182/200\n",
            "\n",
            "Epoch 182: val_loss did not improve from 0.59656\n",
            "1040/1040 - 71s - loss: 0.3665 - accuracy: 0.8689 - val_loss: 0.5993 - val_accuracy: 0.8012 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 183/200\n",
            "\n",
            "Epoch 183: val_loss did not improve from 0.59656\n",
            "1040/1040 - 71s - loss: 0.3673 - accuracy: 0.8686 - val_loss: 0.5968 - val_accuracy: 0.8027 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 184/200\n",
            "\n",
            "Epoch 184: val_loss improved from 0.59656 to 0.59441, saving model to weights\\weights.h5\n",
            "1040/1040 - 71s - loss: 0.3675 - accuracy: 0.8684 - val_loss: 0.5944 - val_accuracy: 0.8033 - lr: 6.2500e-05 - 71s/epoch - 69ms/step\n",
            "Epoch 185/200\n",
            "\n",
            "Epoch 185: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3671 - accuracy: 0.8686 - val_loss: 0.5965 - val_accuracy: 0.8035 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 186/200\n",
            "\n",
            "Epoch 186: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3667 - accuracy: 0.8692 - val_loss: 0.5980 - val_accuracy: 0.8035 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 187/200\n",
            "\n",
            "Epoch 187: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3666 - accuracy: 0.8684 - val_loss: 0.6007 - val_accuracy: 0.8021 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 188/200\n",
            "\n",
            "Epoch 188: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3668 - accuracy: 0.8692 - val_loss: 0.5967 - val_accuracy: 0.8032 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 189/200\n",
            "\n",
            "Epoch 189: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3630 - accuracy: 0.8695 - val_loss: 0.5985 - val_accuracy: 0.8034 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 190/200\n",
            "\n",
            "Epoch 190: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3671 - accuracy: 0.8688 - val_loss: 0.5984 - val_accuracy: 0.8027 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 191/200\n",
            "\n",
            "Epoch 191: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3644 - accuracy: 0.8695 - val_loss: 0.5971 - val_accuracy: 0.8033 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 192/200\n",
            "\n",
            "Epoch 192: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3662 - accuracy: 0.8689 - val_loss: 0.5969 - val_accuracy: 0.8029 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 193/200\n",
            "\n",
            "Epoch 193: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3632 - accuracy: 0.8693 - val_loss: 0.5958 - val_accuracy: 0.8036 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 194/200\n",
            "\n",
            "Epoch 194: val_loss did not improve from 0.59441\n",
            "\n",
            "Epoch 194: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "1040/1040 - 71s - loss: 0.3630 - accuracy: 0.8700 - val_loss: 0.5963 - val_accuracy: 0.8033 - lr: 6.2500e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 195/200\n",
            "\n",
            "Epoch 195: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3618 - accuracy: 0.8699 - val_loss: 0.5971 - val_accuracy: 0.8032 - lr: 3.1250e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 196/200\n",
            "\n",
            "Epoch 196: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3601 - accuracy: 0.8709 - val_loss: 0.5966 - val_accuracy: 0.8040 - lr: 3.1250e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 197/200\n",
            "\n",
            "Epoch 197: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3608 - accuracy: 0.8711 - val_loss: 0.5949 - val_accuracy: 0.8035 - lr: 3.1250e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 198/200\n",
            "\n",
            "Epoch 198: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3615 - accuracy: 0.8706 - val_loss: 0.5964 - val_accuracy: 0.8035 - lr: 3.1250e-05 - 71s/epoch - 68ms/step\n",
            "Epoch 199/200\n",
            "\n",
            "Epoch 199: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3597 - accuracy: 0.8716 - val_loss: 0.5970 - val_accuracy: 0.8036 - lr: 3.1250e-05 - 71s/epoch - 68ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200/200\n",
            "\n",
            "Epoch 200: val_loss did not improve from 0.59441\n",
            "1040/1040 - 71s - loss: 0.3604 - accuracy: 0.8710 - val_loss: 0.5955 - val_accuracy: 0.8033 - lr: 3.1250e-05 - 71s/epoch - 68ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,\n",
        "    Y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=nb_epoch,\n",
        "    verbose=2,\n",
        "    validation_data=(X_val,Y_val),\n",
        "    callbacks = [\n",
        "                keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
        "                keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,verbose=1,patince=5,min_lr=0.0000001),\n",
        "                keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='auto')\n",
        "\n",
        "                ]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1afd946",
      "metadata": {
        "id": "d1afd946",
        "outputId": "5518e7e8-b620-4d9b-f6a2-c83cbd39cf16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14415.526825666428"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TRE_PROPOSED=time.time()\n",
        "T_PROPOSED=TRE_PROPOSED-TRS_PROPOSED\n",
        "T_PROPOSED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d646a26",
      "metadata": {
        "id": "9d646a26"
      },
      "outputs": [],
      "source": [
        "show_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "735e3273",
      "metadata": {
        "id": "735e3273",
        "outputId": "53c474e3-e6bd-4892-90ff-7f37bf530c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "867/867 [==============================] - 17s 20ms/step - loss: 0.5700 - accuracy: 0.8109\n",
            "[0.570003092288971, 0.8109192252159119]\n"
          ]
        }
      ],
      "source": [
        "#Show simple version of performance\n",
        "score = model.evaluate(X_test, Y_test, verbose=1, batch_size=batch_size)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df962f1",
      "metadata": {
        "id": "1df962f1"
      },
      "outputs": [],
      "source": [
        "def predict(model):\n",
        "    model.load_weights(filepath)\n",
        "    # Plot confusion matrix\n",
        "    test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
        "    cm, right, wrong = calculate_confusion_matrix(Y_test, test_Y_hat, classes)\n",
        "    acc = round(1.0 * right / (right + wrong), 4)\n",
        "    print('Overall Accuracy:%.2f%s / (%d + %d)' % (100 * acc, '%', right, wrong))\n",
        "    plot_confusion_matrix(cm, labels=['BPSK',\n",
        "                                      'QPSK',\n",
        "                                      '8PSK',\n",
        "                                      '16PSK',\n",
        "                                      '32PSK',\n",
        "                                      '64PSK',\n",
        "                                      '4QAM',\n",
        "                                      '8QAM',\n",
        "                                      '16QAM',\n",
        "                                      '32QAM',\n",
        "                                      '64QAM',\n",
        "                                      '128QAM',\n",
        "                                      '256QAM',\n",
        "                                      '2FSK',\n",
        "                                      '4FSK',\n",
        "                                      '8FSK',\n",
        "                                      '16FSK',\n",
        "                                      '4PAM',\n",
        "                                      '8PAM',\n",
        "                                      '16PAM',\n",
        "                                      'AM-DSB',\n",
        "                                      'AM-DSB-SC',\n",
        "                                      'AM-USB',\n",
        "                                      'AM-LSB',\n",
        "                                      'FM',\n",
        "                                      'PM'], save_filename='figure/total_confusion.png')\n",
        "    calculate_acc_cm_each_snr(Y_test, test_Y_hat, Z_test, classes, min_snr=-18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a4c6019",
      "metadata": {
        "id": "0a4c6019",
        "outputId": "25bd0300-5755-478b-b3d9-4b8552775bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "867/867 [==============================] - 16s 18ms/step\n",
            "Overall Accuracy:81.06% / (210754 + 49246)\n",
            "Accuracy at -20db: 51.50% / (6700 + 6300)\n",
            "Accuracy at -18db: 53.30% / (6931 + 6069)\n",
            "Accuracy at -16db: 55.50% / (7210 + 5790)\n",
            "Accuracy at -14db: 58.40% / (7597 + 5403)\n",
            "Accuracy at -12db: 60.20% / (7820 + 5180)\n",
            "Accuracy at -10db: 63.30% / (8226 + 4774)\n",
            "Accuracy at -8db: 66.90% / (8694 + 4306)\n",
            "Accuracy at -6db: 71.90% / (9347 + 3653)\n",
            "Accuracy at -4db: 79.00% / (10275 + 2725)\n",
            "Accuracy at -2db: 85.80% / (11152 + 1848)\n",
            "Accuracy at 0db: 92.10% / (11969 + 1031)\n",
            "Accuracy at 2db: 96.30% / (12522 + 478)\n",
            "Accuracy at 4db: 98.00% / (12738 + 262)\n",
            "Accuracy at 6db: 98.30% / (12783 + 217)\n",
            "Accuracy at 8db: 98.40% / (12797 + 203)\n",
            "Accuracy at 10db: 98.40% / (12795 + 205)\n",
            "Accuracy at 12db: 98.50% / (12801 + 199)\n",
            "Accuracy at 14db: 98.50% / (12799 + 201)\n",
            "Accuracy at 16db: 98.50% / (12800 + 200)\n",
            "Accuracy at 18db: 98.40% / (12798 + 202)\n"
          ]
        }
      ],
      "source": [
        "predict(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c439ba",
      "metadata": {
        "id": "25c439ba"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}