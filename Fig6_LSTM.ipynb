{"cells":[{"cell_type":"code","execution_count":null,"id":"72cba5d4","metadata":{"id":"72cba5d4"},"outputs":[],"source":["\"\"\"\n","CLDNN-like LSTM model for RadioML dataset.\n","\n","Reference:\n","- Convolutional + LSTM + Fully Connected Deep Neural Networks\n","- Adapted from code contributed by Mika\n","\"\"\"\n","\n","import os\n","from keras.models import Model\n","from keras.layers import Input, Dense, CuDNNLSTM\n","from keras.utils.vis_utils import plot_model\n","\n","def LSTMModel(weights=None, input_shape=[1024,2], classes=26, **kwargs):\n","    \"\"\"\n","    Builds an LSTM-based classification model.\n","\n","    Arguments:\n","    weights -- path to pre-trained weights file (optional)\n","    input_shape -- shape of input data (samples, timesteps, features)\n","    classes -- number of output classes for classification\n","\n","    Returns:\n","    model -- compiled Keras model\n","    \"\"\"\n","    if weights is not None and not os.path.exists(weights):\n","        raise ValueError('The `weights` argument should be either None (random initialization) or a valid weights file path.')\n","\n","    # Input layer\n","    input = Input(input_shape, name='input')\n","    x = input\n","\n","    # Two stacked LSTM layers using GPU-optimized CuDNNLSTM\n","    x = CuDNNLSTM(units=128, return_sequences=True)(x)  # first LSTM, returns sequences\n","    x = CuDNNLSTM(units=128)(x)                         # second LSTM, outputs last timestep only\n","\n","    # Fully connected output layer with softmax activation for multi-class classification\n","    x = Dense(classes, activation='softmax', name='softmax')(x)\n","\n","    # Define the model\n","    model = Model(inputs=input, outputs=x)\n","\n","    # Load pre-trained weights if provided\n","    if weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n","\n","# Example usage\n","import keras\n","if __name__ == '__main__':\n","    # Instantiate the model\n","    model = LSTMModel(None, input_shape=(1024,2), classes=26)\n","\n","    # Compile the model with Adam optimizer and categorical crossentropy loss\n","    adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n","    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n","\n","    # Save model architecture plot\n","    plot_model(model, to_file='model.png', show_shapes=True)\n","\n","    # Print model details\n","    print('Model layers:', model.layers)\n","    print('Model config:', model.get_config())\n","    print('Model summary:', model.summary())"]},{"cell_type":"code","execution_count":null,"id":"69bfad92","metadata":{"id":"69bfad92"},"outputs":[],"source":["import matplotlib\n","matplotlib.use('TkAgg')  # Use TkAgg backend for interactive plotting\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","import csv\n","import itertools\n","from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, mean_absolute_error, r2_score\n","\n","# ===========================\n","# Function: Plot confusion matrix\n","# ===========================\n","def plot_confusion_matrix(cm, title='', cmap=plt.get_cmap(\"Blues\"), labels=[], save_filename=None):\n","    \"\"\"\n","    Visualizes a confusion matrix with class labels and optional saving as PDF.\n","    \"\"\"\n","    plt.figure(figsize=(10, 7))\n","    plt.imshow(cm*100, interpolation='nearest', cmap=cmap)  # Multiply by 100 to show in %\n","    plt.title(title, fontsize=10)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=90, size=12)\n","    plt.yticks(tick_marks, labels, size=12)\n","\n","    # Annotate each cell with the value\n","    for i in range(len(tick_marks)):\n","        for j in range(len(tick_marks)):\n","            text_color = 'darkorange' if i == j else 'black'\n","            text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10, color=text_color)\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label', fontdict={'size':16})\n","    plt.xlabel('Predicted label', fontdict={'size':16})\n","\n","    # Save figure if filename provided\n","    if save_filename is not None:\n","        plt.savefig(save_filename, format='pdf', dpi=1200, bbox_inches='tight')\n","    plt.close()\n","\n","# ===========================\n","# Function: Calculate confusion matrix\n","# ===========================\n","def calculate_confusion_matrix(Y, Y_hat, classes):\n","    \"\"\"\n","    Computes the normalized confusion matrix and counts of correct and incorrect predictions.\n","    \"\"\"\n","    n_classes = len(classes)\n","    conf = np.zeros([n_classes, n_classes])\n","    confnorm = np.zeros([n_classes, n_classes])\n","\n","    for k in range(Y.shape[0]):\n","        i = list(Y[k,:]).index(1)           # True class index\n","        j = int(np.argmax(Y_hat[k,:]))      # Predicted class index\n","        conf[i,j] += 1\n","\n","    # Normalize each row to sum to 1\n","    for i in range(n_classes):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","\n","    right = np.sum(np.diag(conf))           # Correct predictions\n","    wrong = np.sum(conf) - right            # Incorrect predictions\n","    return confnorm, right, wrong\n","\n","# ===========================\n","# Function: Calculate per-class accuracy from confusion matrix\n","# ===========================\n","def calculate_acc_at1snr_from_cm(cm):\n","    \"\"\"\n","    Returns the recognition accuracy per class from the confusion matrix.\n","    \"\"\"\n","    return np.round(np.diag(cm) / np.sum(cm, axis=1), 3)\n","\n","# ===========================\n","# Function: Compute standard metrics\n","# ===========================\n","def calculate_metrics(Y, Y_hat):\n","    \"\"\"\n","    Computes accuracy, precision, recall, F1-score, MSE, MAE, and R2 score.\n","    \"\"\"\n","    Y_true = np.argmax(Y, axis=1)\n","    Y_pred = np.argmax(Y_hat, axis=1)\n","\n","    accuracy = accuracy_score(Y_true, Y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(Y_true, Y_pred, average='weighted')\n","\n","    mse = mean_squared_error(Y_true, Y_pred)\n","    mae = mean_absolute_error(Y_true, Y_pred)\n","    r2 = r2_score(Y_true, Y_pred)\n","\n","    return accuracy, precision, recall, f1\n","\n","# ===========================\n","# Function: Calculate metrics per SNR and optionally plot\n","# ===========================\n","def calculate_acc_cm_each_snr(Y, Y_hat, Z, classes=None, save_figure=True, min_snr=0):\n","    \"\"\"\n","    Computes accuracy, precision, recall, and F1-score for each SNR level.\n","    Optionally generates plots of metrics vs SNR.\n","    \"\"\"\n","    Z_array = Z[:, 0]  # Extract SNR values\n","    snrs = sorted(list(set(Z_array)))  # Unique SNR levels\n","    acc_mod_snr = np.zeros((len(classes), len(snrs)))\n","\n","    metrics = {\n","        'accuracy': [],\n","        'precision': [],\n","        'recall': [],\n","        'f1': []\n","    }\n","\n","    # Loop over each SNR and compute metrics\n","    for snr in snrs:\n","        Y_snr = Y[np.where(Z_array == snr)]\n","        Y_hat_snr = Y_hat[np.where(Z_array == snr)]\n","\n","        accuracy, precision, recall, f1 = calculate_metrics(Y_snr, Y_hat_snr)\n","        metrics['accuracy'].append(accuracy)\n","        metrics['precision'].append(precision)\n","        metrics['recall'].append(recall)\n","        metrics['f1'].append(f1)\n","\n","    # Plot metrics vs SNR\n","    for metric, values in metrics.items():\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(snrs, values, label=metric)\n","        for x, y in zip(snrs, values):\n","            plt.text(x, y, round(y, 3), ha='center', va='bottom', fontsize=8)\n","        plt.xlabel(\"Signal to Noise Ratio (dB)\")\n","        plt.ylabel(metric.capitalize())\n","        plt.title(f\"{metric.capitalize()} vs SNR\")\n","        plt.legend()\n","        plt.grid()\n","        plt.savefig(f'figure/{metric}_vs_snr.pdf', format='pdf', dpi=1200, bbox_inches='tight')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"6c68633a","metadata":{"id":"6c68633a"},"outputs":[],"source":["# -----------------------------\n","# Setup environment and imports\n","# -----------------------------\n","# Set Keras backend to TensorFlow and choose GPU device 3\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n","\n","# Import standard libraries for computation, plotting, and data handling\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from matplotlib.collections import LineCollection\n","from matplotlib.colors import ListedColormap, BoundaryNorm\n","import pickle, random, sys, h5py\n","import keras\n","import keras.backend as K\n","from keras.callbacks import LearningRateScheduler, TensorBoard\n","from keras.regularizers import *\n","from keras.optimizers import Adam\n","from keras.models import model_from_json\n","import tensorflow as tf\n","from keras.utils.np_utils import to_categorical\n","import pandas as pd\n","\n","# -----------------------------\n","# Function to convert I/Q data to amplitude and phase\n","# -----------------------------\n","def to_amp_phase(X_train, X_val, X_test, nsamples):\n","    \"\"\"\n","    Convert complex-valued I/Q signals to amplitude and normalized phase representation.\n","\n","    Arguments:\n","    X_train, X_val, X_test -- input datasets with shape (samples, nsamples, 2) representing I/Q components\n","    nsamples -- number of samples per signal\n","\n","    Returns:\n","    X_train, X_val, X_test -- transformed datasets in shape (samples, nsamples, 2) with amplitude and phase\n","    \"\"\"\n","\n","    # Convert I/Q to complex numbers\n","    X_train_cmplx = X_train[:, :,0] + 1j * X_train[:, :,1]\n","    X_val_cmplx   = X_val[:, :,0] + 1j * X_val[:, :,1]\n","    X_test_cmplx  = X_test[:, :,0] + 1j * X_test[:, :,1]\n","\n","    # Compute amplitude and normalized phase for training set\n","    X_train_amp = np.abs(X_train_cmplx)\n","    X_train_ang = np.arctan2(X_train[:, :,1], X_train[:, :,0]) / np.pi\n","\n","    # Reshape and concatenate amplitude & phase\n","    X_train_amp = np.reshape(X_train_amp, (-1, 1, nsamples))\n","    X_train_ang = np.reshape(X_train_ang, (-1, 1, nsamples))\n","    X_train = np.concatenate((X_train_amp, X_train_ang), axis=1)\n","    X_train = np.transpose(X_train, (0, 2, 1))  # shape -> (samples, nsamples, 2)\n","\n","    # Repeat the same transformation for validation set\n","    X_val_amp = np.abs(X_val_cmplx)\n","    X_val_ang = np.arctan2(X_val[:, :,1], X_val[:, :,0]) / np.pi\n","    X_val_amp = np.reshape(X_val_amp, (-1, 1, nsamples))\n","    X_val_ang = np.reshape(X_val_ang, (-1, 1, nsamples))\n","    X_val = np.concatenate((X_val_amp, X_val_ang), axis=1)\n","    X_val = np.transpose(X_val, (0, 2, 1))\n","\n","    # Repeat the same transformation for test set\n","    X_test_amp = np.abs(X_test_cmplx)\n","    X_test_ang = np.arctan2(X_test[:, :,1], X_test[:, :,0]) / np.pi\n","    X_test_amp = np.reshape(X_test_amp, (-1, 1, nsamples))\n","    X_test_ang = np.reshape(X_test_ang, (-1, 1, nsamples))\n","    X_test = np.concatenate((X_test_amp, X_test_ang), axis=1)\n","    X_test = np.transpose(X_test, (0, 2, 1))\n","\n","    return (X_train, X_val, X_test)\n","\n","# -----------------------------\n","# Define modulation classes for classification\n","# -----------------------------\n","classes = ['BPSK','QPSK','8PSK','16PSK','32PSK','64PSK',\n","           '4QAM','8QAM','16QAM','32QAM','64QAM','128QAM','256QAM',\n","           '2FSK','4FSK','8FSK','16FSK','4PAM','8PAM','16PAM',\n","           'AM-DSB','AM-DSB-SC','AM-USB','AM-LSB','FM','PM']"]},{"cell_type":"code","execution_count":null,"id":"ba31a143","metadata":{"id":"ba31a143"},"outputs":[],"source":["# ===========================\n","# Load training data\n","# ===========================\n","data1 = h5py.File('Dataset/HisarMod2019.1/Train/train.mat','r')  # Open .mat file in read mode\n","train = data1['data_save'][:]                                   # Extract dataset from HDF5 group 'data_save'\n","\n","# Swap axes to match model input shape\n","# Original shape might be (num_samples, 2, 1024) or (1024, 2, num_samples)\n","# After swapaxes(0,2), shape becomes (num_samples, 2, 1024)\n","train = train.swapaxes(0,2)\n","\n","# ===========================\n","# Load test data\n","# ===========================\n","data2 = h5py.File('Dataset/HisarMod2019.1/Test/test.mat','r')\n","test = data2['data_save'][:]\n","test = test.swapaxes(0,2)\n","\n","# ===========================\n","# Add channel dimension\n","# ===========================\n","# Conv2D layers expect input of shape (samples, height, width, channels)\n","train = np.expand_dims(train, axis=3)  # Add a channel dimension: shape -> (num_samples, 2, 1024, 1)\n","test = np.expand_dims(test, axis=3)"]},{"cell_type":"code","execution_count":null,"id":"53a104dd","metadata":{"id":"53a104dd"},"outputs":[],"source":["# ===========================\n","# Load and preprocess labels\n","# ===========================\n","\n","# Load training labels from CSV file\n","train_labels = pd.read_csv('Dataset/HisarMod2019.1/Train/train_labels1.csv', header=None)\n","train_labels = np.array(train_labels)  # Convert DataFrame to NumPy array\n","\n","# Convert integer labels to one-hot encoding\n","# This is required for categorical cross-entropy loss in Keras\n","train_labels = to_categorical(train_labels, num_classes=None)\n","\n","\n","# Load test labels from CSV file\n","test_labels = pd.read_csv('Dataset/HisarMod2019.1/Test/test_labels1.csv', header=None)\n","test_labels = np.array(test_labels)    # Convert DataFrame to NumPy array\n","test_labels = to_categorical(test_labels, num_classes=None)  # One-hot encoding\n","\n","\n","# ===========================\n","# Load and preprocess SNR values\n","# ===========================\n","\n","# Load training SNR values from CSV\n","# Each row corresponds to the SNR of a training sample\n","train_snr = pd.read_csv('Dataset/HisarMod2019.1/Train/train_snr.csv', header=None)\n","train_snr = np.array(train_snr)  # Convert to NumPy array for easier indexing\n","\n","# Load test SNR values from CSV\n","# Each row corresponds to the SNR of a test sample\n","test_snr = pd.read_csv('Dataset/HisarMod2019.1/Test/test_snr.csv', header=None)\n","test_snr = np.array(test_snr)    # Convert to NumPy array"]},{"cell_type":"code","execution_count":null,"id":"32fa9c2e","metadata":{"id":"32fa9c2e"},"outputs":[],"source":["# -----------------------------\n","# Split dataset into training, validation, and test sets\n","# -----------------------------\n","\n","n_examples = train.shape[0]                # Total number of examples in the training dataset\n","n_train = int(n_examples * 0.8)            # 80% for training\n","n_val = int(n_examples * 0.2)              # 20% for validation\n","\n","# Randomly select indices for training samples\n","train_idx = list(np.random.choice(range(0, n_examples), size=n_train, replace=False))\n","\n","# Validation indices are the remaining indices not in training set\n","val_idx = list(set(range(0, n_examples)) - set(train_idx))\n","\n","# Shuffle the indices to avoid any ordering bias\n","np.random.shuffle(train_idx)\n","np.random.shuffle(val_idx)\n","\n","# Use the selected indices to extract the actual data and labels\n","X_train = train[train_idx]                 # Training input features\n","Y_train = train_labels[train_idx]          # Training labels\n","X_val = train[val_idx]                     # Validation input features\n","Y_val = train_labels[val_idx]              # Validation labels\n","\n","# Test set (already predefined)\n","X_test = test\n","Y_test = test_labels\n","Z_test = test_snr                           # SNR values corresponding to test samples\n","\n","# Convert I/Q data to amplitude and phase representation for all sets\n","# After this, each sample will have shape (nsamples, 2) where the two channels are amplitude and normalized phase\n","X_train, X_val, X_test = to_amp_phase(X_train, X_val, X_test, 1024)"]},{"cell_type":"code","execution_count":null,"id":"1b345a40","metadata":{"id":"1b345a40"},"outputs":[],"source":["# Set up some params\n","nb_epoch =  200  # number of epochs to train on\n","batch_size = 300  # training batch size"]},{"cell_type":"code","execution_count":null,"id":"b5bcef38","metadata":{"id":"b5bcef38"},"outputs":[],"source":["# -----------------------------\n","# Create and compile the LSTM model\n","# -----------------------------\n","\n","model = LSTMModel()  # Instantiate the LSTM-based model with default input shape (1024,2) and number of classes (26)\n","\n","# Compile the model specifying:\n","# - Loss function: categorical crossentropy (used for multi-class classification)\n","# - Metrics: accuracy (to monitor training and validation performance)\n","# - Optimizer: Adam (adaptive learning rate optimizer)\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n","\n","# Print a summary of the model architecture\n","# This includes each layer's type, output shape, and number of parameters\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"18c70f5b","metadata":{"id":"18c70f5b"},"outputs":[],"source":["plot_model(model, to_file='model_LSTM.png',show_shapes=True) # print model"]},{"cell_type":"code","execution_count":null,"id":"9b34c952","metadata":{"id":"9b34c952"},"outputs":[],"source":["# -----------------------------\n","# Train the LSTM model\n","# -----------------------------\n","\n","filepath = 'weights/weights.h5'  # Path to save the best model weights during training\n","\n","import time\n","TRS_LSTM = time.time()  # Record start time for training duration measurement\n","\n","# Train the model using model.fit\n","history = model.fit(\n","    X_train,                # Training features\n","    Y_train,                # Training labels (one-hot encoded)\n","    batch_size=batch_size,  # Number of samples per gradient update\n","    epochs=nb_epoch,        # Number of training epochs\n","    verbose=2,              # Verbosity mode (2 = one line per epoch)\n","    validation_data=(X_val,Y_val),  # Validation dataset for monitoring overfitting\n","    callbacks=[             # List of callbacks during training\n","        keras.callbacks.ModelCheckpoint(\n","            filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'\n","        ),  # Save the model weights only when validation loss improves\n","        keras.callbacks.ReduceLROnPlateau(\n","            monitor='val_loss', factor=0.5, verbose=1, patince=5, min_lr=1e-6\n","        ),  # Reduce learning rate by 0.5 if validation loss plateaus for 5 epochs\n","        keras.callbacks.EarlyStopping(\n","            monitor='val_loss', patience=5, verbose=1, mode='auto'\n","        ),  # Stop training early if validation loss does not improve for 5 epochs\n","        # keras.callbacks.TensorBoard(...)  # Optional: visualize training in TensorBoard\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"id":"ea30fa81","metadata":{"id":"ea30fa81"},"outputs":[],"source":["TRE_LSTM = time.time()       # Record the end time after training completes\n","T_LSTM = TRE_LSTM - TRS_LSTM # Calculate total training duration in seconds"]},{"cell_type":"code","execution_count":null,"id":"a3f6a412","metadata":{"id":"a3f6a412"},"outputs":[],"source":["TES_LSTM = time.time()  # Record the start time before evaluating the LSTM model on the test set"]},{"cell_type":"code","execution_count":null,"id":"b9d97a78","metadata":{"id":"b9d97a78"},"outputs":[],"source":["#Show simple version of performance\n","score = model.evaluate(X_test, Y_test, verbose=1, batch_size=batch_size)\n","print(score)"]},{"cell_type":"code","execution_count":null,"id":"ca4bf8f0","metadata":{"id":"ca4bf8f0"},"outputs":[],"source":[" calculate_acc_cm_each_snr(Y_test, test_Y_hat, Z_test, classes, min_snr=-18) #Accuracy"]},{"cell_type":"code","execution_count":null,"id":"dd3d9e4e","metadata":{"id":"dd3d9e4e"},"outputs":[],"source":["TEE_LSTM = time.time()  # Record the end time after evaluating the LSTM model on the test set\n","T_LSTM_E = TEE_LSTM - TES_LSTM  # Calculate the time taken for LSTM model evaluation on the test set"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}