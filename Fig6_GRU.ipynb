{"cells":[{"cell_type":"code","execution_count":null,"id":"024fa850","metadata":{"id":"024fa850"},"outputs":[],"source":["import os\n","from keras.models import Model\n","from keras.layers import Input, Dense, CuDNNGRU\n","from keras.utils.vis_utils import plot_model\n","\n","# ===========================\n","# Define a GRU-based classification model\n","# ===========================\n","def GRUModel(weights=None,\n","             input_shape=[1024,2],\n","             classes=26,\n","             **kwargs):\n","\n","    # Check if provided weights file exists\n","    if weights is not None and not (os.path.exists(weights)):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization), '\n","                         'or the path to the weights file to be loaded.')\n","\n","    # Input layer: shape = (timesteps, features)\n","    input = Input(input_shape, name='input')\n","    x = input\n","\n","    # ===========================\n","    # GRU Layers\n","    # ===========================\n","    # First GRU layer: returns sequences for stacking\n","    x = CuDNNGRU(units=128, return_sequences=True)(x)\n","    # Second GRU layer: returns the last output for classification\n","    x = CuDNNGRU(units=128)(x)\n","\n","    # ===========================\n","    # Fully connected layer for classification\n","    # ===========================\n","    x = Dense(classes, activation='softmax', name='softmax')(x)\n","\n","    # Create the model\n","    model = Model(inputs=input, outputs=x)\n","\n","    # Load pre-trained weights if provided\n","    if weights is not None:\n","        model.load_weights(weights)\n","\n","    return model\n","\n","# ===========================\n","# Model compilation and summary\n","# ===========================\n","import keras\n","if __name__ == '__main__':\n","    # Initialize model with example input shape and number of classes\n","    model = GRUModel(None, input_shape=(128, 2), classes=11)\n","\n","    # Adam optimizer with default parameters\n","    adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n","    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n","\n","    # Visualize the model architecture\n","    plot_model(model, to_file='model.png', show_shapes=True)  # Generates an image of the model\n","\n","    # Print detailed model information\n","    print('Model layers:', model.layers)        # List all layers\n","    print('Model config:', model.get_config())  # Configuration of the model\n","    print('Model summary:', model.summary())   # Full summary with output shapes and parameters"]},{"cell_type":"code","execution_count":null,"id":"b28daad2","metadata":{"id":"b28daad2"},"outputs":[],"source":["import matplotlib\n","matplotlib.use('TkAgg')  # Use TkAgg backend for interactive plotting\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","import csv\n","import itertools\n","from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, mean_absolute_error, r2_score\n","\n","# ===========================\n","# Function: Plot confusion matrix\n","# ===========================\n","def plot_confusion_matrix(cm, title='', cmap=plt.get_cmap(\"Blues\"), labels=[], save_filename=None):\n","    \"\"\"\n","    Visualizes a confusion matrix with class labels and optional saving as PDF.\n","    \"\"\"\n","    plt.figure(figsize=(10, 7))\n","    plt.imshow(cm*100, interpolation='nearest', cmap=cmap)  # Multiply by 100 to show in %\n","    plt.title(title, fontsize=10)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=90, size=12)\n","    plt.yticks(tick_marks, labels, size=12)\n","\n","    # Annotate each cell with the value\n","    for i in range(len(tick_marks)):\n","        for j in range(len(tick_marks)):\n","            text_color = 'darkorange' if i == j else 'black'\n","            text = plt.text(j, i, int(np.around(cm[i,j]*100)), ha=\"center\", va=\"center\", fontsize=10, color=text_color)\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label', fontdict={'size':16})\n","    plt.xlabel('Predicted label', fontdict={'size':16})\n","\n","    # Save figure if filename provided\n","    if save_filename is not None:\n","        plt.savefig(save_filename, format='pdf', dpi=1200, bbox_inches='tight')\n","    plt.close()\n","\n","# ===========================\n","# Function: Calculate confusion matrix\n","# ===========================\n","def calculate_confusion_matrix(Y, Y_hat, classes):\n","    \"\"\"\n","    Computes the normalized confusion matrix and counts of correct and incorrect predictions.\n","    \"\"\"\n","    n_classes = len(classes)\n","    conf = np.zeros([n_classes, n_classes])\n","    confnorm = np.zeros([n_classes, n_classes])\n","\n","    for k in range(Y.shape[0]):\n","        i = list(Y[k,:]).index(1)           # True class index\n","        j = int(np.argmax(Y_hat[k,:]))      # Predicted class index\n","        conf[i,j] += 1\n","\n","    # Normalize each row to sum to 1\n","    for i in range(n_classes):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","\n","    right = np.sum(np.diag(conf))           # Correct predictions\n","    wrong = np.sum(conf) - right            # Incorrect predictions\n","    return confnorm, right, wrong\n","\n","# ===========================\n","# Function: Calculate per-class accuracy from confusion matrix\n","# ===========================\n","def calculate_acc_at1snr_from_cm(cm):\n","    \"\"\"\n","    Returns the recognition accuracy per class from the confusion matrix.\n","    \"\"\"\n","    return np.round(np.diag(cm) / np.sum(cm, axis=1), 3)\n","\n","# ===========================\n","# Function: Compute standard metrics\n","# ===========================\n","def calculate_metrics(Y, Y_hat):\n","    \"\"\"\n","    Computes accuracy, precision, recall, F1-score, MSE, MAE, and R2 score.\n","    \"\"\"\n","    Y_true = np.argmax(Y, axis=1)\n","    Y_pred = np.argmax(Y_hat, axis=1)\n","\n","    accuracy = accuracy_score(Y_true, Y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(Y_true, Y_pred, average='weighted')\n","\n","    mse = mean_squared_error(Y_true, Y_pred)\n","    mae = mean_absolute_error(Y_true, Y_pred)\n","    r2 = r2_score(Y_true, Y_pred)\n","\n","    return accuracy, precision, recall, f1\n","\n","# ===========================\n","# Function: Calculate metrics per SNR and optionally plot\n","# ===========================\n","def calculate_acc_cm_each_snr(Y, Y_hat, Z, classes=None, save_figure=True, min_snr=0):\n","    \"\"\"\n","    Computes accuracy, precision, recall, and F1-score for each SNR level.\n","    Optionally generates plots of metrics vs SNR.\n","    \"\"\"\n","    Z_array = Z[:, 0]  # Extract SNR values\n","    snrs = sorted(list(set(Z_array)))  # Unique SNR levels\n","    acc_mod_snr = np.zeros((len(classes), len(snrs)))\n","\n","    metrics = {\n","        'accuracy': [],\n","        'precision': [],\n","        'recall': [],\n","        'f1': []\n","    }\n","\n","    # Loop over each SNR and compute metrics\n","    for snr in snrs:\n","        Y_snr = Y[np.where(Z_array == snr)]\n","        Y_hat_snr = Y_hat[np.where(Z_array == snr)]\n","\n","        accuracy, precision, recall, f1 = calculate_metrics(Y_snr, Y_hat_snr)\n","        metrics['accuracy'].append(accuracy)\n","        metrics['precision'].append(precision)\n","        metrics['recall'].append(recall)\n","        metrics['f1'].append(f1)\n","\n","    # Plot metrics vs SNR\n","    for metric, values in metrics.items():\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(snrs, values, label=metric)\n","        for x, y in zip(snrs, values):\n","            plt.text(x, y, round(y, 3), ha='center', va='bottom', fontsize=8)\n","        plt.xlabel(\"Signal to Noise Ratio (dB)\")\n","        plt.ylabel(metric.capitalize())\n","        plt.title(f\"{metric.capitalize()} vs SNR\")\n","        plt.legend()\n","        plt.grid()\n","        plt.savefig(f'figure/{metric}_vs_snr.pdf', format='pdf', dpi=1200, bbox_inches='tight')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"d9e14cca","metadata":{"id":"d9e14cca"},"outputs":[],"source":["import os, random\n","\n","# Set Keras backend to TensorFlow\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","\n","# Uncomment if you want to select a specific GPU (here GPU 0)\n","# os.environ[\"THEANO_FLAGS\"]  = \"device=gpu%d\"%(0)\n","\n","# Make only GPU 0 visible to TensorFlow/Keras\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","# matplotlib.use('Tkagg')  # Optional: Use TkAgg backend for interactive plotting\n","import matplotlib.pyplot as plt\n","from matplotlib.collections import LineCollection\n","from matplotlib.colors import ListedColormap, BoundaryNorm\n","import pickle, random, sys, h5py\n","\n","import keras\n","import keras.backend as K\n","from keras.callbacks import LearningRateScheduler, TensorBoard\n","from keras.regularizers import *\n","from keras.optimizers import Adam\n","from keras.models import model_from_json\n","from keras.utils.np_utils import to_categorical\n","\n","# ===========================\n","# Define modulation classes\n","# ===========================\n","# This list represents all modulation schemes in the HisarMod2019.1 dataset\n","classes = ['BPSK', 'QPSK', '8PSK', '16PSK', '32PSK', '64PSK',\n","           '4QAM', '8QAM', '16QAM', '32QAM', '64QAM', '128QAM', '256QAM',\n","           '2FSK', '4FSK', '8FSK', '16FSK',\n","           '4PAM', '8PAM', '16PAM',\n","           'AM-DSB', 'AM-DSB-SC', 'AM-USB', 'AM-LSB',\n","           'FM', 'PM']\n","\n","# Each element in the list is used as a target class label when converting labels\n","# to one-hot vectors using `to_categorical()` during training and evaluation."]},{"cell_type":"code","execution_count":null,"id":"5e7ff188","metadata":{"id":"5e7ff188"},"outputs":[],"source":["# ===========================\n","# Load training data\n","# ===========================\n","data1 = h5py.File('Dataset/HisarMod2019.1/Train/train.mat','r')  # Open .mat file in read mode\n","train = data1['data_save'][:]                                   # Extract dataset from HDF5 group 'data_save'\n","\n","# Swap axes to match model input shape\n","# Original shape might be (num_samples, 2, 1024) or (1024, 2, num_samples)\n","# After swapaxes(0,2), shape becomes (num_samples, 2, 1024)\n","train = train.swapaxes(0,2)\n","\n","# ===========================\n","# Load test data\n","# ===========================\n","data2 = h5py.File('Dataset/HisarMod2019.1/Test/test.mat','r')\n","test = data2['data_save'][:]\n","test = test.swapaxes(0,2)\n","\n","# ===========================\n","# Add channel dimension\n","# ===========================\n","# Conv2D layers expect input of shape (samples, height, width, channels)\n","train = np.expand_dims(train, axis=3)  # Add a channel dimension: shape -> (num_samples, 2, 1024, 1)\n","test = np.expand_dims(test, axis=3)"]},{"cell_type":"code","execution_count":null,"id":"6e5334f2","metadata":{"id":"6e5334f2"},"outputs":[],"source":["# ===========================\n","# Load and preprocess labels\n","# ===========================\n","\n","# Load training labels from CSV file\n","train_labels = pd.read_csv('Dataset/HisarMod2019.1/Train/train_labels1.csv', header=None)\n","train_labels = np.array(train_labels)  # Convert DataFrame to NumPy array\n","\n","# Convert integer labels to one-hot encoding\n","# This is required for categorical cross-entropy loss in Keras\n","train_labels = to_categorical(train_labels, num_classes=None)\n","\n","\n","# Load test labels from CSV file\n","test_labels = pd.read_csv('Dataset/HisarMod2019.1/Test/test_labels1.csv', header=None)\n","test_labels = np.array(test_labels)    # Convert DataFrame to NumPy array\n","test_labels = to_categorical(test_labels, num_classes=None)  # One-hot encoding\n","\n","\n","# ===========================\n","# Load and preprocess SNR values\n","# ===========================\n","\n","# Load training SNR values from CSV\n","# Each row corresponds to the SNR of a training sample\n","train_snr = pd.read_csv('Dataset/HisarMod2019.1/Train/train_snr.csv', header=None)\n","train_snr = np.array(train_snr)  # Convert to NumPy array for easier indexing\n","\n","# Load test SNR values from CSV\n","# Each row corresponds to the SNR of a test sample\n","test_snr = pd.read_csv('Dataset/HisarMod2019.1/Test/test_snr.csv', header=None)\n","test_snr = np.array(test_snr)    # Convert to NumPy array"]},{"cell_type":"code","execution_count":null,"id":"d306e7b9","metadata":{"id":"d306e7b9"},"outputs":[],"source":["# ===========================\n","# Split dataset into training and validation sets\n","# ===========================\n","\n","# Number of total examples in the training dataset\n","n_examples = train.shape[0]  # train has shape [N, 1024, 2]\n","\n","# Number of samples for training and validation\n","n_train = int(n_examples * 0.8)  # 80% for training\n","n_val = int(n_examples * 0.2)    # 20% for validation\n","\n","# Randomly select indices for training samples\n","train_idx = list(np.random.choice(range(0, n_examples), size=n_train, replace=False))\n","\n","# Remaining indices will be used for validation\n","val_idx = list(set(range(0, n_examples)) - set(train_idx))\n","\n","# Shuffle indices to ensure random ordering\n","np.random.shuffle(train_idx)\n","np.random.shuffle(val_idx)\n","\n","# ===========================\n","# Create datasets using the indices\n","# ===========================\n","\n","# Training data and labels\n","X_train = train[train_idx]         # Shape: [n_train, 1024, 2]\n","Y_train = train_labels[train_idx]  # Shape: [n_train, num_classes]\n","\n","# Validation data and labels\n","X_val = train[val_idx]             # Shape: [n_val, 1024, 2]\n","Y_val = train_labels[val_idx]      # Shape: [n_val, num_classes]\n","\n","# Test data and labels (use full test set)\n","X_test = test                     # Shape: [num_test_samples, 1024, 2]\n","Y_test = test_labels               # Shape: [num_test_samples, num_classes]\n","\n","# Test SNR values corresponding to each test sample\n","Z_test = test_snr                  # Shape: [num_test_samples, 1] or similar"]},{"cell_type":"code","execution_count":null,"id":"ae580183","metadata":{"id":"ae580183"},"outputs":[],"source":["# Set up some params\n","nb_epoch = 200     # number of epochs to train on\n","batch_size = 300  # training batch size"]},{"cell_type":"code","execution_count":null,"id":"63a9c7e6","metadata":{"id":"63a9c7e6"},"outputs":[],"source":["# Initialize the GRU model using the defined GRUModel function\n","model = GRUModel()\n","\n","# Compile the model\n","# - Loss: categorical_crossentropy (since it's a multi-class classification problem)\n","# - Metrics: accuracy (to monitor training and validation performance)\n","# - Optimizer: Adam (adaptive learning rate optimizer)\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","# Visualize and save the model architecture\n","# - 'to_file': specifies the filename for the diagram\n","# - 'show_shapes=True': displays the input/output shapes of each layer\n","plot_model(model, to_file='model_CLDNN.png', show_shapes=True)  # Print model architecture to file\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"2a6d51fe","metadata":{"id":"2a6d51fe"},"outputs":[],"source":["# File path to save the best model weights during training\n","filepath = 'weights/weights.h5'\n","\n","# Record the start time for training\n","import time\n","TRS_GRU = time.time()\n","\n","# Train the GRU model\n","history = model.fit(\n","    X_train,                # Training data\n","    Y_train,                # Training labels\n","    batch_size=batch_size,  # Number of samples per gradient update\n","    epochs=nb_epoch,        # Total number of training epochs\n","    verbose=2,              # Display training progress (1: progress bar, 2: one line per epoch)\n","    validation_data=(X_val, Y_val),  # Validation data to monitor performance\n","    callbacks=[             # List of callbacks executed during training\n","        # Save the best model based on validation loss\n","        keras.callbacks.ModelCheckpoint(\n","            filepath,\n","            monitor='val_loss',\n","            verbose=1,\n","            save_best_only=True,\n","            mode='auto'\n","        ),\n","        # Reduce learning rate when validation loss plateaus\n","        keras.callbacks.ReduceLROnPlateau(\n","            monitor='val_loss',\n","            factor=0.5,       # Reduce LR by factor 0.5\n","            verbose=1,\n","            patince=5,        # (Typo: should be 'patience') Wait 5 epochs before reducing LR\n","            min_lr=0.000001   # Minimum learning rate allowed\n","        ),\n","        # Stop training early if validation loss does not improve\n","        keras.callbacks.EarlyStopping(\n","            monitor='val_loss',\n","            patience=5,       # Stop after 5 epochs without improvement\n","            verbose=1,\n","            mode='auto'\n","        )\n","        # Optional TensorBoard callback (commented out)\n","        # keras.callbacks.TensorBoard(log_dir='./logs/', histogram_freq=1, write_graph=False, write_grads=1, write_images=False, update_freq='epoch')\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"id":"d4ea4e98","metadata":{"id":"d4ea4e98"},"outputs":[],"source":["import time\n","\n","# Record the end time after training\n","TRE_GRU = time.time()\n","\n","# Calculate the total training duration for the GRU model\n","TR_GRU = TRE_GRU - TRS_GRU"]},{"cell_type":"code","execution_count":null,"id":"9c9c0a27","metadata":{"id":"9c9c0a27"},"outputs":[],"source":["# Record the start time for testing/evaluation\n","TES_GRU = time.time()\n","\n","# Evaluate the trained GRU model on the test set\n","# Returns [loss, accuracy] because the model was compiled with metrics=['accuracy']\n","score = model.evaluate(X_test, Y_test, verbose=1, batch_size=batch_size)\n","\n","# Print the evaluation results (loss and accuracy)\n","print(score)"]},{"cell_type":"code","execution_count":null,"id":"9b84b6f6","metadata":{"id":"9b84b6f6"},"outputs":[],"source":["calculate_acc_cm_each_snr(Y_test, test_Y_hat, Z_test, classes, min_snr=-18) # Accuracy"]},{"cell_type":"code","execution_count":null,"id":"c716ea50","metadata":{"id":"c716ea50"},"outputs":[],"source":["# Record the end time after testing/evaluation\n","TEE_GRU = time.time()\n","\n","# Compute the total time taken for evaluating the model on the test set\n","TE_GRU = TEE_GRU - TES_GRU"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}